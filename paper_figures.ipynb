{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48024a4d",
   "metadata": {},
   "source": [
    "# Modeling Partial Orders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11f38c8",
   "metadata": {},
   "source": [
    "Code accompanying the paper \"Statistical Modeling of Top-$k$ Partial Orders\" by Amel Awadelkarim and Johan Ugander."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd15a52",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5912f3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis and Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import random\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "import networkx as nx\n",
    "import collections\n",
    "\n",
    "# Modeling\n",
    "import src.stratified_pytorch as sp\n",
    "import src.data_processing as dp\n",
    "\n",
    "# Plotting\n",
    "import seaborn as sns\n",
    "sns.set_theme(style='whitegrid', rc={'grid.alpha': 0.25, 'text.usetex': False})\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "\n",
    "# Misc\n",
    "import sys # For library installation\n",
    "import re # For regex\n",
    "from glob import glob # For parsing directories\n",
    "from tqdm import tqdm\n",
    "import importlib\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76009cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69d969d6-eb4a-42a3-9900-97067fff40c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.data_processing' from '/home/ameloa/partial-orders/src/data_processing.py'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ed936ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pref_voter_id</th>\n",
       "      <th>year</th>\n",
       "      <th>race</th>\n",
       "      <th>first_report_seen</th>\n",
       "      <th>vote_rank</th>\n",
       "      <th>candidate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>['LONDON BREED', 'JOEL VENTRESCA']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2019</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>['LONDON BREED']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>2019</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6]</td>\n",
       "      <td>['JOEL VENTRESCA', 'PAUL YBARRA ROBERTSON', 'E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>2019</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>['LONDON BREED']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>2019</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6]</td>\n",
       "      <td>['LONDON BREED', 'PAUL YBARRA ROBERTSON', 'WIL...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pref_voter_id  year race first_report_seen           vote_rank  \\\n",
       "0             0  2019    M                 1              [1, 2]   \n",
       "1             2  2019    M                 1                 [1]   \n",
       "2             5  2019    M                 1  [1, 2, 3, 4, 5, 6]   \n",
       "3             8  2019    M                 1                 [1]   \n",
       "4            10  2019    M                 1  [1, 2, 3, 4, 5, 6]   \n",
       "\n",
       "                                           candidate  \n",
       "0                 ['LONDON BREED', 'JOEL VENTRESCA']  \n",
       "1                                   ['LONDON BREED']  \n",
       "2  ['JOEL VENTRESCA', 'PAUL YBARRA ROBERTSON', 'E...  \n",
       "3                                   ['LONDON BREED']  \n",
       "4  ['LONDON BREED', 'PAUL YBARRA ROBERTSON', 'WIL...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "data_root = 'data/'\n",
    "paths = [os.path.join(data_root, name) for name in os.listdir(data_root) if name.endswith('.csv')]\n",
    "elections_df = pd.concat([pd.read_csv(path, low_memory=False) for path in paths], ignore_index=True).drop(columns='Unnamed: 0')\n",
    "elections_df['year'] = elections_df['year'].map(str)\n",
    "elections_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce9809e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Repeated selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11d0df9-f0b4-4a56-9210-8fa335ab8087",
   "metadata": {},
   "source": [
    "Converting ranking objects into choice observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbea035c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcv_datasets = collections.defaultdict(dict)\n",
    "for year in elections_df.year.unique():\n",
    "    for race in elections_df.race.unique():\n",
    "        subset_df = elections_df.query('year==@year & race==@race')\n",
    "        if not subset_df.empty:\n",
    "            rcv_datasets[year][race] = dp.sfrcv_clean_dataframe(subset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00843c58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. agents:\t\t178924\n",
      "No. alternatives:\t7\n",
      "Avg. len of ranking:\t2.628141377345208\n",
      "No. training examples:\t461186\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "K-fold cross val for selecting hyperparams\n",
    "'''\n",
    "year='2019'\n",
    "race='M'\n",
    "dataset = rcv_datasets[year][race]\n",
    "\n",
    "kfolds=5\n",
    "shuffled = dataset.sample(frac=1).reset_index(drop=True)\n",
    "folds = np.array_split(shuffled, kfolds)\n",
    "dataset = pd.concat(folds)\n",
    "\n",
    "'''\n",
    "Convert rankings to choices\n",
    "'''\n",
    "choices, agents_codex, alternatives_codex, ballot = dp.prep_dataset(dataset, end_token=False)\n",
    "\n",
    "num_alternatives = len(alternatives_codex)\n",
    "num_agents = len(agents_codex)\n",
    "print('No. agents:\\t\\t{}'.format(num_agents))\n",
    "print('No. alternatives:\\t{}'.format(num_alternatives))\n",
    "print('Avg. len of ranking:\\t{}'.format(dataset.num_ranked.mean()))\n",
    "print('No. training examples:\\t{}'.format(choices[0].shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41082b15",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f802441-91bb-44fd-9e69-78e190d3e59f",
   "metadata": {},
   "source": [
    "Model hyperameter selection for the length-dependent composite model and stratified augmented model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739a6903",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Length-dependent composite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "caed4be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_strat_sweep(i, length_k, length_reg):\n",
    "    result=[]\n",
    "    val = folds[i]\n",
    "    train = pd.concat([df for j, df in enumerate(folds) if j!=i])\n",
    "\n",
    "    train_choices, train_agent_codex, train_alt_codex, train_ballot = dp.prep_dataset(train)\n",
    "    (xval, xlval, yval), val_agent_codex = dp.prep_valset(val, train_alt_codex)\n",
    "    \n",
    "    num_observations = train_choices[0].shape[0]\n",
    "    num_agents = len(train_agent_codex)\n",
    "    num_alternatives = len(train_alt_codex)\n",
    "    max_length = train_ballot.length.max()\n",
    "    length_k = min(length_k, max_length)\n",
    "\n",
    "    kwargs={'mnl_fixed_effects': True,\n",
    "            'categorical': True,\n",
    "            'dependent': True,\n",
    "            'max_length': max_length,\n",
    "            'length_k': length_k,\n",
    "            'length_reg': length_reg\n",
    "           }\n",
    "    model, tr_loss, no_params, num_epochs, runtime, tr_losses, _ = sp.train(ds=train_choices, \n",
    "                                                                            num_items=len(train_alt_codex), \n",
    "                                                                            alternative_codex=train_alt_codex, \n",
    "                                                                            epochs=2000, \n",
    "                                                                            lr=1e-3, \n",
    "                                                                            wd=1e-5, \n",
    "                                                                            verbose=True, \n",
    "                                                                            Model=sp.JointModel,\n",
    "                                                                            **kwargs)\n",
    "    task_loss = tr_loss - np.array(tr_losses)[-1, -1]\n",
    "    result.append(['length dependent', i, length_k, length_reg, 'train', task_loss, num_epochs, runtime, no_params])\n",
    "    result.append(['length dependent', i, length_k, length_reg, 'train + reg', tr_loss, num_epochs, runtime, no_params])\n",
    "    \n",
    "    yval_hat = model.forward(xval, xlval)\n",
    "    v_loss, v_loss_terms = model.loss_func(yval_hat, yval, xval, xlval, train=False)\n",
    "    result.append(['length dependent', i, length_k, length_reg, 'val', float(v_loss), num_epochs, runtime, no_params])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4b239c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n"
     ]
    }
   ],
   "source": [
    "length_ks = [1,2,3,5,10,15]\n",
    "length_regs = [0.0, 1e-3, 1e-2, 0.1]\n",
    "\n",
    "strat_results = Parallel(n_jobs=30)(delayed(length_strat_sweep)(i, length_k, length_reg) \n",
    "                                    for i in range(kfolds) \n",
    "                                    for length_k in length_ks\n",
    "                                    for length_reg in length_regs)\n",
    "strat_results = [item for sublist in strat_results for item in sublist]\n",
    "strat_results_df = pd.DataFrame(strat_results, columns=['model', 'fold', 'length k', 'length reg', 'loss type', 'loss', 'num epochs', 'runtime', 'no params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c13955f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtAAAAEeCAYAAACjXSLFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABTp0lEQVR4nO3dd3hU1dbH8W8aEGooCigqIrIFadKkFwVULCDYe8ELonJRr3pfK1dFVEAQFSlSBGnSe5cqIEU6sinSO4GEmkiSef/IGIMmkAnJTM6Z38dnHoezz5mzFgkrK3v2ORPi8XgQEREREZGMCQ10ACIiIiIiTqIGWkRERETEB2qgRURERER8oAZaRERERMQHaqBFRERERHygBlpERERExAdqoMURjDF9jTHvBToOERHJOGNMY2PMvkDHIZLVwgMdgAQHY8wuoK21dm5mjrfWts/aiEREREQyRzPQEnDGGP0iJyIiIo6hxkWynTFmGHAtMMUYkwh8CHwGtAU+AHYBDY0xY4AGQCSwDnjRWrvJ+xpDgH3W2neNMY2BH4CewFtAIvC2tXawH9MSEQkaxpi3gJrW2gdSbfsSCAHWAG8CpYCjwGfW2n4BCVTETzQDLdnOWvsksAe411qbH/jRO9QIKA/c4f3zDOBG4ErgV2D4RV62BFAIuBp4HvjGGFM466MXERFgFNDCGFMAwBgTBjwEjACOAPcABYFngZ7GmGqBClTEHzQDLYHU2Vp75s8/WGsH/fncGNMZOGGMKWStjU3j2PPAh9baBGC6MeY0YIDl2RyziEjQsdbuNsb8CtwPDAVuA85aa/9ecxcaY2aT/G7ir34OU8Rv1EBLIO3984l3NqML8CBwBZDkHSoGpNVAR3ub5z+dBfJnU5wiIpI82/woyQ30Y94/Y4y5i+TleOVIfmc7L7AhQDGK+IWWcIi/eC6x7TGgJdCU5KUZpb3bQ7I3LBERyaAxQGNjTCmSZ6JHGGNyA+OA7kBxa20UMB3VbnE5NdDiL4eBMhcZLwDEA9Ekz1584o+gREQkY6y1R4EFwGBgp7X2NyAXkJvkiwcTvLPRzQMWpIifqIEWf+kKvGuMiQEeSGN8KLAb2A9sRmuZRURyohEkv1M4AsBaewroSPLF4SdIfjdxcsCiE/GTEI8nrXfWRUREREQkLZqBFhERERHxgRpoEREREREfqIEWEREREfGBGmgRERERER+ogRYRERER8YEjP4nw/LHfdesQEReIKFYm0x+24EsduJzzyOVTzRZxh8utpW6q245soEVESDwf6AhERMQXLqrbaqBFxJmSkgIdgYiI+MJFdVsNtIg4ksfjnkIsIhIM3FS31UCLiDO5aCZDRCQouKhuq4EWEWdy0UyGiEhQyIa6bYzpDrQBSgOVrLUb09nvIeA9IATwAE2ttYeNMVcCg4FrgAhgPtDRWptwsfPqNnYi4kxJiRl/iIhI4GVP3Z4INAR2p7eDMaYG0BloZq2tCNQHYr3DbwO/WWsrA5WB6kDrS51UM9Ai4kyJF50cEBGRnMaHum2MiQKi0hiKsdbG/PkHa+0S7/4Xe7lXge7W2kPeY2JTjXmAAsaYUCA3kAvYf6n41ECLiCO56WIUEZFg4GPd7gR8kMb2/5E8m+yLCsBOY8wiID8wHuhirfUAHwHjgINAPuBra+3Pl3pBNdAi4kwuuhhFRCQo+Fa3ewFD0tgek4kzh5G8PKMZyTPMM4E9wFDgQWA9cDtQAJhhjHnAWjv2Yi+oBlpEnEkz0CIizuJD3fYu04jJojPvAcZaa+OBeGPMJKAWyQ30K8Bz1tokINY71gS4aAOtiwhFxJl0EaGIiLMErm6PAJobY0KMMREkzzav847tBO4EMMbkApoCad7JIzU10CLiTJ6kjD9ERCTwsqFuG2N6G2P2AaWAucaYTd7t07133wAYBRwBNgNrgU3AQO9YJ6CBMWaDd2wrMOBS5w3xeDwZDjKnOH/sd+cFLSL/EFGsTEhmj43fOCfDdSB3xWaZPo9cPtVsEXe4nJoN7qrbWgMtIs6kiwhFRJzFRXVbDbSIOJLHo7XNIiJO4qa6rQZaRJxJa5tFRJzFRXVbDTTw7idfsOjnFRQpHMXEH/qmuc+KX9fz2Zf9SEhIoHBUQYZ8042du/fxn/e7puyz78BBXm77JE8+fL+/Qs805ayc/+TYnF30VqBcWma/lwGGjprAuCkzCQkJ4cYbSvPx26+RO3eulOM+6fktE6bNZuXcCX7JJaOUs3L+k2tydlHdVgMNtGrRjMfa3MfbH3VPc/zkqdN83ONr+vX4mJIlriT6RAwA119XinHffwNAYmIit7V6ktsb1fVX2JdFOf+TcnZYzonnAx2B+FFmv5cPHz3G8LGTmDS8H3ly5+b19z5hxtyFtLq7GQAbf9vKyVOn/ZWGT5TzPylnh+fsorqt29gBNapWolDBAumOT5+zgKaN6lGyxJUAFC0c9Y99lq9ayzVXl+SqEsWzK8wspZz/STk7LGfdxi6oXM73ckJiIvHxf5CQkMi5uHiuKFYESP7lsMc3A3m9w/PZGntmKed/Us4Oz9lFdVsz0Bmwa88+EhITeeblNzl79hyPP9iSlnc1vWCfGfMW0qJpowBFmPWUs3L+U47NOZveCjTGdAfaAKWBStbaNG+ob4x5CHgPCAE8QFNr7eFLjUn2SO97ufgVxXjm0TY0bf0UeXLnom7NatS7tToAI8ZNoUn92ilNh9MoZ+XsuJxdtIQj4DPQ3htX52iJiUls3rKNPt0+pN8XH9NvyEh27dmXMn7+/HkWLPmF5rc1CGCUWUs5K2fI4Tln30zGRKAhsDu9Hbw35+8MNLPWVgTqA7GXGpPsk973cuzJU8xfvJxZYwbz06ThnIuLZ8qsnzhyNJrZ8xfz2AP3BTr0TFPOytlxOWsG2jfGmAoXGS7qjxguR/Eri1GoUAHyRuYhb2QeqletiN2+k9LXlgJg8fJVlC93A8WKFA5wpFlHOStnyOE5+zCTYYyJAqLSGIqx1sak3mCtXeI95mIv+SrQ3Vp7yHtMbAbHJJuk970McPVVxSnifdv79kZ1WbthMwUL5GfPvoO0ePg5AOLi4rnroeeY8eOgQKXgM+WsnB2Xs2agfbYRmApMS+NRzE8xZFqTBrVZs36Td41RHBs2WcqUviZlfPqcBbRo1jhwAWYD5aycIYfnnJSU8UfyR7XuTOPRKZNnrwCUMcYsMsb8aox51xgTkoExySbpfS+XLH4F6zdu4VxcHB6Ph19WraXMddfQqG4tFk4Zwexx3zN73PfkyZM7ZzQYPlDOytlxOftWt3M0f62B3gU0sNbu//uAMWavn2JI1xsffMrKNeuJiTnJ7a2eoMPzT5KQkADAw/ffzQ2lr6XerTVo/fSLhIaE0ubeO7ixTGkAzp6LY9nKNXzwZscAZuA75aycnZ6zx7eruXsBQ9LYHpPJ04cBlYFmQC5gJrAHGHqJMcmky/lebtakPg89+wphYWHcVO4GHmx5VwAzyTjlrJzdlrOPdTtHC/F4Mvyx5JlmjOkGTLDWLk1j7Etr7b99eb3zx37P/qBFJNtFFCuT6ZnZc/O/y3AdiGzS1ufzGGN2AfekdRGhMWYq8KO1dqj3z28C11prX77YmK8xuIVqtog7XE7Nhuyv2/7klxloa+0bFxnzqXkWEQEC/RbfCKCFMWYYyXX0dmBsBsZERIKXA5ZmZFTA78IhIpIp2XQ1tzGmtzFmH1AKmGuM2eTdPt17hw2AUcARYDOwFtgEDMzAmIhI8HLRXTj8soQjq+ntQBF3uKwlHLP7ZPytwOYdcvRbgW6nmi3iDpe9hMNFdVsfpCIizpSYEOgIRETEFy6q22qgRcSZXLSWTkQkKLiobquBFhFncsAaORERScVFdVsNtIg4k4tmMkREgoKL6rYaaBFxJhfNZIiIBAUX1W010CLiTC6ayRARCQouqttqoEXEmVx0NbeISFBwUd1WAy0izuSimQwRkaDgorqtBlpEnMmBHwIlIhLUXFS31UCLiDO5aCZDRCQouKhuq4EWEWdyUSEWEQkKLqrbaqBFxJlcdDskEZGg4KK6rQZaRJwpMTHQEYiIiC9cVLfVQIuIM7norUARkaDgorrtyAb6gWodAx2C30WEhAY6BL8qE5Iv0CH43TtNjgY6BL8rNHhu5g92USF2u3qVnw10CH4XSkigQ/C76yKiAh2C331z04lAh+BXxWYtvLwXcFHddmQDLSLiprV0IiJBwUV1Ww20iDiSJ8k99xMVEQkGbqrbaqBFxJlc9JGwIiJBIRvqtjGmO9AGKA1UstZuTGe/h4D3gBDAAzS11h6+1Fh6gmthrYi4R5In4w8REQm87KnbE4GGwO70djDG1AA6A82stRWB+kDspcYuRjPQIuJMLroYRUQkKGRD3bbWLgEwxlxst1eB7tbaQ95jYjM4li410CLiTGqgRUScxYe6bYyJAqLSGIqx1sb4eOYKwE5jzCIgPzAe6GKt9VxiLF1awiEizuTxZPwhIiKB51vd7gTsTOPRKRNnDgMqA82ARsBdwJMZGEuXZqBFxJk0Ay0i4iy+1e1ewJA0tsdk4sx7gLHW2ngg3hgzCagFDL3EWLrUQIuIM7noI2FFRIKCD3Xbu0wjJovOPAJoYYwZRnLvezswNgNj6dISDhFxJt2FQ0TEWbKhbhtjehtj9gGlgLnGmE3e7dO9d9gAGAUcATYDa4FNwMAMjKVLM9Ai4kgeLeEQEXGU7Kjb1tqOQMc0trdI9TwJeM37+Pt+6Y5djBpoEXEmzSyLiDiLi+q2GmgRcSaPZqBFRBzFRXVbDbSIOJOLZjJERIKCi+q2GmgRcaYE3YVDRMRRXFS31UCLiDO56K1AEZGg4KK6rQYaeKXbv6lxe01io2Pp2Oylf4xXrF2Jt797l8N7DwOwfOZSRn85CoB7nruP5o/eQUgIzB45iykDJ/s19szq0K0j1W+rQWx0LK81f+Uf4zfXrsibA97hiDfnX2YuY2zv0QC0ePZemj7anJCQEOaOnM20Qc7I+cHP21H+tls4HX2SL+54M819ytQuz33vP0VoeDhnT5yi78MfAlCuURVavv8UIWGhrBg9nwXfOiPnyOf+Q3iVW/GcjOH0ey+kuU+YqULkYy9CWDieU7Gc+ez1vwZDQsn/QR+SThzj7Jfv+inqDHLRW4Fyae9+8Rb1m9bhxLETPHrbs/8Yr1anKt0Hd+HA3oMAzJ++mIE9vwfg4efb0OrxewgJCWHi8KmM+i75Fq8vvP4MLR+7h5jjMQD06TqApT/94p+EMuCdL96kXtM6nDgWw+Pp5Pz54I85sPcQAAumL2JQz+TPfnjo+Ta0fPweQkJg0vBpjPbm3Pb1Z7jvsbuJOR4LwLddB7AsB+XcvtvLVLutBiejY/lP83+nuU+F2hV5+v3nCYsI49Txk/zv4eTaVKXRLTzzQVtCw0L5adQcJn07HoB2n7/MDZVugJAQDu48QJ/XexN/Ns5vOV1K/tfeItetdUiKOUFMu39+nQEiKlclX/uXITwcT2wssW+k+rsJDSXqq/4kRR/l5Pv/d8Fx+V7sSJ477iK61V3ZmULGuahuq4EG5o2Zy7Tvp9KpZ/p3MNm8chMfP/vhBduuLXcdzR+9g//c+xoJ58/TediHrJy7kkO7D2Z3yJdt/ph5zPh+Kq988Wq6+2xZuZmuz310wbZryl1L00eb89/7XifhfALvDu3M6nnOyHnV2IUs/X4WD3/RIc3xPAXzcv9HzzHw6U+JORBNvqIFAQgJDeH+D59lwBOfEHsomlcmd2HznNUc2b7fn+Fnyh9LZhE/byJ5276V9g6R+Yh8siNnvvg/PMePEFIg6oLhXM3uJ/HgHkLy5M3+YH2k29gFl2mjZzBm8Hg6f/l2uvus/WU9rz19YQNRxlxPq8fv4Zm725PwRwJfjvicJXOXsW9X8r/fkQPGMLzv6GyNPbOmjZ7J2METeP+iOW/gP2nk3PLxe3jOm3OvEZ/zc6qcRw0Yy4gcmvPCMT8x6/vpvPRF2s1z3oL5eP7jdnzy1P+IPnCMgkULARASGspzH7Wjy+MfEH0omq6Tu7Fq7gr2b9vH0A8Hcu70OQCefO9Z7ny6RUpznRPEzZ7BucnjKfBG2l/nkHz5yffyq5x85w2Sjh4hpFDUBeN5Wj1Awt7dhOa9sE6H32gIyV8gu8LOFDfVbX2QCrB5xSZOx5zy+bhSN5Zi6xrLH3HxJCUmsXH5RurcVTcbIsx6v63YxOmY0z4fV6rsNWxbu5U/4v4gKTGJzb9s4tY762RDhFlv54otnI1NP+db7qvHxpkriTkQDcCZ6JMAXFO1LMd2H+L43iMknk9k3ZRl3Ny8Rrqvk5Mkbt2A53T639u5at/O+V+X4Dl+BADPqZiUsZDCxYiocit/LJqe3WFmTjZ9kIoxprsxZqcxxmOMqXiR/R4yxmwwxmz0/r/438aNMeasMaZ7JjOUVNb8sp6TJ3yv09ffeB2b1vxG/Ll4EhMT+XXZOpq0aJgNEWa9tZnMufSN17JpzeZUOa+lcYsG2RBh1vttxeaL/myq37IhK2YuI/rAMQBORifPpJeteiOHdx3kyN7DJJ5PYOmUJdRsditASvMMkCt3LjyenDULmrBxPZ5T6X+dczdpyh8/LyLpqLdOx8akjIUWu4JctWoTP2PqhQeFhpL3hRc5M/Db7Ag581z0AVhqoDPIVLuJXjO/4v3vO3NNuWsB2GN3U6HWzRSIKkCuPLmp3qQGxUoWC3CkWadcNUP3GV/yzvcfUOrGawDYs3U35WtWIH9UAXLlycUtTapT9Cp35FysTEkiC+Wj3aj36DilC9VaJ//AKVS8MLHephog9mA0BYsXDlSYWSq0xNWE5M1Pvrd6kP+DPkTUbZYyFvloB879OCDnFrLExIw/fDMRaAjsTm8H76dbdQaaWWsrAvWB2FTjYUA/72uJn1SqfjPD5wyk1w+fU6ZcaQB2bNlJ1VqVKVS4ILkjc1PvttoUv+rKlGMefPZ+hs8dxLtfvEWBQvkDFHnmVapegWFzvqPnD59xvTfn3705F/TmXDeNnH+YO5B3vnjTcTmXvP4q8hXKz/ujPqbr1B40bN0YgCIlihB98FjKftEHoylcokjKn1/s9gr9Vg3h6rKlmDlkmr/DvixhpUoRkr8AhT7vRdTX/cnd9I6UsXztX+bMd33hb78U5Lnvfv5Y9jOe48f9He7FZV/d9ju/LOEwxhQFPgOuBSZZa79JNTbOWtvGH3Fk1o6N23mhznPEnY2jepMavD3gXV5s9C/2bd/H+G/H0nn4R8SfjWPn5t9JcsnbE79v3MGLddsSdzaOW5pU560B7/BK4/bs376PiX3H894P/yP+bDy7Nu0kKdEdOYeGhXJ1pevp/1gXIvLk4uXx/2PPmm2BDit7hYURVrocZz5/g5Bcucj3bm8Sd2wmtEQpkk7FkLR7G2GmSqCjTFs2NfbW2iUAxpiL7fYq0N1ae8h7TOzfxv8LTAXyex+SzeyGrdxX62HOnT1H3dtu5fNBXXig/uPs2r6boX1G0Htkd+LOxrF103YSvT+cx30/iYE9h+LxeGj/5vP8+4OX+Pi1zwKcScZt2bCVVrUe4dzZc9S57VY+H/QxD9Z/gl3b9zCsz0h6j+zGubNxbNu0nURvnR7//SQGeXNu9+ZzdPygA11e+zzAmWRcaHgoZSrewEePvU+uPLn4aMJnbFuz9ZLHffvGV8nLPD58gbr31mfBmJ/8EG0WCQsj/MZyxL71GiG5cxPVqw/nf9tEWKlrSIqJIXH7VkIrV03ZPbRIUXI3aEzsG50CFnK6cuqETCb4aw10P+B3YDrwojHmduAha20CUMZPMWRa6rd/Vs9fRbuPX6RA4YKcOnGSuaPnMHf0HACeePOpC34DdrLUOa+Zv5qwj9pToHABTp04xU+j5/CTN+fH3niS6EPuyDn20HHOxpzm/Ll4zp+L5/cVWyhZ/jpiDx2n0FVFU/YrVLIoJw+fCGCkWcdz/BgJp0/CH3F4/ogj0W4g9JobCCt9IxFV6xBRuRZE5CIkT14i//VfzvX/NNAhp/D4UIiNMVFAVBpDMdbamEycvgKw0xiziOQGeTzQxVrrMcZUAe4AmgDvZeK1JRPOnD6b8nzpT7/wZtcwChUpROzxWCaPnM7kkclLkV787wscOXgUgOPH/vp3PHH4VL4Y2tW/QV+ms6lyXvbTL4R3fTUl5ykjpzPFm3P7/7blaBo5Txo+je4Oy/n4wWhOnzhF/Ll44s/F89uKzVxXvjTRh6Ipmuod4KIli3Li0IWzr56kJJZOXsy97e93VAOddPQo50+ehPg4PPFxnN+wjvAyZQkveyO5atclV81bCcmVi5C8+cj/5jvEL5hH2FVXU3jw8OQXyJ2HwoOHc+LZxwObCL7V7ZzOX0s4brTWvmmtHQ80Bw4CU40xefx0/ssSdUVUyvMbq5QjNDSEUyeS18cW8l7AUOyqK6hzZx0WTVoYiBCzXOqcy1a5kZDQUE551+IVTMm5GLfeWYfFkxYFIsQst3n2KkrXMISGhRKRJxfXVi3Lke372bduB8VKl6BwqSsIiwijyr112DxndaDDzRLn1ywl/MaKEBoKuXITVuYmkg7uIX7sQE69/iin3niCs992IeG3tTmqeQZ8XUvXCdiZxqNTJs8eBlQGmgGNgLuAJ40xEUB/oL21Nue/B+kiRa/46+36ClVvIjQ0lFjvnSYKF40CoPjVV9KkRQNmTZibfMyVfx3T+K4G7LA7/RdwFijyt5xDQkPSzLlxi4bMmjAPuDDnRnfV53eH5bxqzgpMzQqEhoWSK08ubqx6I/u372PHum2UuL4kV1xzJWER4dS9tz6r5qwAoPh1JVKOr96sFgd25PwLwFP7Y9nPhN9cCULDIHduwm8qT+Ke3ZwdPIATTzzIiacf4VTXDzm/7ldOf96F8yuWc/zR1px4+hFOPP0IxMfliOYZcNUaaH/NQOf684m11gO8ZIzpBkwDAt5Ev/7VG1SsU4mChQsy8JchjPxiOOERyX81M3+YQd0W9bnrybtITEjij7h4ur/819tdb/V7m4KFC5BwPpF+7/XlzMkzgUrDJ516/4eb61SkQOGC9Fs+iNE9RxIeHgbA7OEzqd2iHnc8cReJCYn8EfcHvV7plnLsG33/S/7CBUg8n8h37/flrENyfqz3K5SpXZ58hQvw9rKvmdNzLGHer/Py4XM5suMAWxeu49WZn+FJ8rBi9HwOb90HwKT3h9B26P8RGhbKyh8XcHjbvkCmkmGR7d4m/KYqhOQvRIEeI4mb+D0hYck5/7FgKkkH93B+wyryfzgAPEn8sWgGSft3BTbojPJtuVQvYEga22MyefY9wFhrbTwQb4yZBNQCFgA3ANO9S0CigBBjTEFr7b8yeS4BPurzPtXrVCWqSCGmrBrDgB6DCQ9P/l4eP2wyt93TiDZPtSQxIZG4uHjeefF/Kcd+9t1HFCxckMTzCXR7uxenTyZfpPbKuy9S7uayeDweDu47RNc3c9b1nh/2eY9q3pwn/y3nCd6cWz91H4kJicTH/cF7L/51p6iu331IocIFSTifQPdUOb/8bntuvLkseHP+9M0eAcktPR17v0YF78+mPsu/Y0zPUYR5fzbNHT6L/dv3sW7hr3Sb9SWepCR+GjWXvVv3ADDo/QG8PfQDQsPCWPDjXPZt20tISAgvffFvIvPnJSQEdv+2i+/e6RvIFP+hwH/fJ6JyVUIKFaLwD2M4O2wwId6vc9y0ySTu3c35VSuI6jsIPEnEzZxG4m5n/eKTwiXLXAFC/HE1qjFmGvCZtXbR37Z/ArxlrQ3z5fVaXntPzv/VJItFhATX9Z5lQvIFOgS/e6fJ0UCH4HeFBs8NyeyxpzrcleE6UKDPDJ/PY4zZBdxjrd2YxthjQAvgSZInIqaS3FAP+Nt+nYH81tr/+Hp+N6l1VaOgq9mhZPpb27Gui4gKdAh+981N7ljOl1HFZi28rG/s7K7b/uSvruxJYMPfN1pr3wYq+SkGEXERT2JShh++MMb0NsbsA0oBc40xm7zbp3vvvgEwCjgCbAbWApuAgVmVm4iIG2VX3Q4EvyzhsNamex8Va+1mf8QgIi6TfXfh6Ah0TGN7i1TPk4DXvI+LvVbnrI5PRMSxHLC2OaP0SYQi4kwuKsQiIkHBRXVbDbSIOJKbbockIhIM3FS31UCLiDO5qBCLiAQFF9VtNdAi4kw5/xoTERFJzUV1Ww20iDiSJ8FFlVhEJAi4qW6rgRYRZ3JPHRYRCQ4uqttqoEXEkdx0MYqISDBwU91WAy0izuSimQwRkaDgorqtBlpEHMlNMxkiIsHATXVbDbSIOJInIdARiIiIL9xUt9VAi4gzueitQBGRoOCiuq0GWkQcyeOiQiwiEgzcVLfVQIuIM7moEIuIBAUX1W010CLiSG6ayRARCQZuqttqoEXEkdxUiEVEgoGb6rYaaBFxJE9iSKBDEBERH7ipbjuygZ4fvTnQIfhdWEhooEPwq9/yFQ10CH53z4xrAx2C3zW8jGPdNJPhdrvPHA50COIHMbnPBDoEv1u2rmygQ/Crey/zeDfVbUc20CIiniT3zGSIiASD7KjbxpjuQBugNFDJWrsxnf0eAt4DQgAP0NRaezjVuAHWAH2stf+51HmDa1pTRFzDk5Txh4iIBF421e2JJL+huTu9HYwxNYDOQDNrbUWgPhCbajwM6Od9rQzRDLSIOJLHoxloEREnyY66ba1dApA8gZyuV4Hu1tpD3mNi/zb+X2AqkN/7uCQ10CLiSEkJaqBFRJzEl7ptjIkCotIYirHWxvh46grATmPMIpIb5PFAF2utxxhTBbgDaELyEo8M0RIOEXEkjyfjDxERCTwf63YnYGcaj06ZOHUYUBloBjQC7gKeNMZEAP2B9tbaRF9eUDPQIuJIuohQRMRZfKzbvYAhaWyPycSp9wBjrbXxQLwxZhJQC1gA3ABM9y4BiQJCjDEFrbX/utgLqoEWEUdSAy0i4iy+1G3vMo2YLDr1CKCFMWYYyb3v7SQ31HuAYn/uZIzpDOTXXThExLW0hENExFmyo24bY3obY/YBpYC5xphN3u3TvXffABgFHAE2A2uBTcDAy8lFM9Ai4kiagRYRcZbsqNvW2o5AxzS2t0j1PAl4zfu42Gt1zuh51UCLiCMluegjYUVEgoGb6rYaaBFxpCTdB1pExFHcVLfVQIuII+mDVEREnMVNdVsNtIg4ktZAi4g4i5vqthpoEXEk3V1DRMRZ3FS31UCLiCO5aSZDRCQYuKluq4EWEUdKTNJt7EVEnMRNdds9mVyGb779jB27VrB85Yw0x+s3uJW9B9axZNlUliybylv/fQWAsjden7JtybKp7Du4jg4vPevP0DPtqz5d2brzF5aumJ7meL0Gt7J7/xoWLZ3MoqWTeeO/LwPJOf+5bdHSyew+sJb2HZ7xY+SZ91Gvd1m0aQYTF45Ic7xm3Wos3zaPcfOGMW7eMF587fmUsafaPcKkhSOZuHAE3fp+RK7cufwV9mUp1/NFam/8juoLeqS7T6G6Fag2txvVF35B5Qn/AyD3VUWpPO4Dqi/qSfWFX3BV2xbpHh8o2fVBKsaY7saYncYYjzGm4kX2e8gYs8EYs9H7/+Le7e8ZYzYZY9YbY1YbY+64vEwFoNfXXdi0/WcWLpuc5njd+rXYtmcl8xZPYN7iCbz2ZoeUsXYdnmbh8iksXDaZvgN7kDvVv9//e68TS1fPZPGKabRt92S25+GLYMy5S6/3+HnTLCYvHJXmeK261Vi5fT4TfhrOhJ+G0+H1tiljT77wCJMXjmLKotE89a9HU7bfce/tTFk0ms2HfqFilfLZnoOvqvRsR/ONfWm04PN09ylatzwN53al8cJu1J3wPgB5ripCnXHv0nhRNxov7Mb1be+84JjSz99Bk8XdabywG+Xfeyxbc8goN30AlmaggeE/jKV/v6H0G9A93X2WLV3JQw+0vWDb9m07qV/nHgBCQ0Ox25cxZfKsbI01q4wcPp4B/X6g74Bu6e6zbOlKHnnwwo+C375tJw3r3gck57x5289MmzI7W2PNKhNHTWXEwDF0/fqDdPdZ/ctaXnri9Qu2XVniCh5v+zD3NXiE+Lh4evTvQotWzZg4elp2h3zZDo9ewIFBMzFfvZzmeFjBvJT99AU2PtqF+P3HiChWEABPQiK/dx7K6Q07CcuXh1tmf0bMovWc3brPn+FfVDbeDmki8CWwOL0dvJ9u1Rm4zVp7yBhTCIj3Dq8AelhrzxpjqgALjTElrbXnsivgYDBqxAQGDhjO130/TXefX5at5omH21+wrUTJK2nb/kka1LqbuLh4+g/pSas2dzN6xAQeebw1V11dgno17sLj8VCsWJHsTsMnwZjzhFFTGT7wRz79+n/p7rN6+RraP3Hh52HceNMNPPhEKx6682nO/5HAgNG9WTBnMXt27mPblh10fPZN/tf9/7I7/EzZO3ohuwbNoupXHdIcDy+Yl0qfPscvj37Kuf3R5Eqp00ls7vwDsRt2EZYvDw1nf8LRRRs4vXU/RetVoMQd1Vl4+39J+iMh5ZhAc9Nt7DI8A22MyZuVJzbGFM7K17scS39eyYnjMZf1Go2b1GXn77vZu/dA1gSVzZb+vJITJ2Iu6zUaNa7Lrt/3OCbn1cvXEhtzMlPHhoWFkSdP7uT/583DkUPHsji67BG7/DfOx5xOd/zK1vWJnvYL8fuT8zl/LPnv548jMZzesBOAxDNxnN22n1wlctYPWo8nJMMPX1hrl1hr915it1eB7tbaQ95jYq21cd7ns6y1Z737rQdCgKK+ZSd/t3zpKmJOxGbq2LCwMPJE5iEsLIy8kZEcOnQEgGeef4Qen/fB453uOnbseJbFmxWCMedVy9dkqk6XubE063/dSNy5eBITE1m59Fea3d0EgN+37WLnjt1ZHWqWOb58C39cpE5f3boeB6et5Nz+aAD+8Nbp+CMxxG7YBSTX6dPb9pPHW6dLP92M7V9NJumPhAuOCbTsqtuB4MsSjqFpbTTGXPK9bGNMFe9bmSuMMeWNMdOA/caYvcaYqj7EEDC1at3Cz8unMW7CIG4qf+M/xts8cC9jx0wJQGTZp2atW1i8bApjxg9MM+fWD9zNuLFTAxBZ9qlavRLjf/qBviN6coO5HoAjh44y5NvhzP11EgvWT+P0ydMsXfhLgCPNGpFlriI8Kh+Vx3fmllmfceWDDf+xT+5rriB/xes59eu2AESYPl/eCjTGRBljSqfxiMrk6SsAZYwxi4wxvxpj3jXGpFXxnwJ2WGtzztS9i1WvVZWflkxkxNj+mJvKAnDo4BG+/WoQv278ifVbF3Py5CkW/vQzANddfy2tWt/FrAVjGTG2P9eXuS6Q4WdKMOZctUYlJs4fTv+RX1LWlAFg25Yd1KhdlajChcgTmZtGTetS8qriAY40a+QvU5KIqHzUGf8eDWZ1odSDDf6xT+Q1xShUsTQxv24HIF+ZEhSpfRP1p39E3QnvU6hqGX+HnSY3LeHwpYGON8a8m3qDMaYEsDADx/YG/gd8DcwERlhr8wIdgPTXTeQQ69Zu4ubyDahX+2769R3KyFH9LhiPiIigRYvbmTAh7TXUTrR+7SYqV2hEgzr30r/vUH4Y+e0F4xEREdx19+1MnJD2Gmon2rze0qx6S1rf9gTDB47hqyHJy1sKFirAbXc2pHnN+2lS5W4i80ZyT5s7L/FqzhASHkb+ymXY+ERXNjz6Mde9+gCRZUqmjIfmzUOF7/7DjvcHk3g6Z61ASEwKzfAD6ATsTOPRKZOnDwMqA82ARsBdwAWLSY0xjYCPgEf/cbRkufXrNlG94m3cVr8VA/v9wJARXwNQKKogd959OzUrN6WKaUjevJG0eeheAHLniiAu7g/uaPwAP3w/hl7fdAlkCj4Lxpw3rbfcVv0+WjV5nB++G83X3yfX6d+37WLAV0MZ+ONXDBjVm982biUxMSnA0WaNkPBQoipfz4onPueXRz/lxlfvJ1+ZEinjYXlzU+O7V9n4/lASvHU6JDyMXFH5WdLiPTZ/OJwa/f8dqPAv4GPdztF8ifAFoLUx5h4AY0w1ktf6ZWQKsoC1drK1diiAtXa49/9TcMBbm6dOnebMmeR3ZGfPWkB4RDhFiv61AqVZ80asW7eJo0ec8bZ+RqTOec7shUT8LeemzRuxbu1mjh6JDlSIWe7M6TOcPZtcfBbPW0p4eBhRRQpRu2FN9u05wInoGBISEpk7bT631KwU4Gizxh8HojmxYB1JZ+NJOH6K2OW/ke/m5BmpkPAwKgx8nSPjFxM9fUWAI/2nJE9Ihh9AL+D6NB69Mnn6PcBYa228tfYUMAmo9eegMaYO8APQylprM5ujZNzpU2c4661Z8+YsIjw8giJFomjYuA57du8jOvoECQkJTJsyh5q33gLAgQOHme69hmP6lDlUuNkELP7MCMacz5w+w9kzyXV60bylRISHE1WkEADjRkymTbOneLJlO07GnGLX73sCGWqWiTtwnCML1pN4Np4/jp/i+PItFExVp2sMfJX943/m0PSVFxxz0Fu3Y9bswJPkIVfRAgGJPzUf63aOdtEG2rv0IheAd01fa6C3MeYNYAbwirU2I7++pv6b+PsVZzn+14wrixdLeV69emVCQ0M5Hn0iZduDD97LGJct37jyyr9yrpZGzg88eA/jXJZzsSv+WuNb6ZYKhIaGEnM8loP7D1OlWkXyROYGoHaDmuzYtitAUWatY7NWUrDWTRAWSmhkLgpUK8vZbfuB5Dt4nN22n/39cuYyHY8PD2ttjLV2VxqPmEyefgTQ3BgTYoyJAG4H1gEYY2oCo4EHrLW/Zj5D8cUVqWrWLdUqERoawvHjMezfe5BqNaoQGZkHgAaN6rDN/g7AzGlzqdfgViD5jhY7duzye9yXIxhzLnblX3NulW6pQIi3TgMUKZY8yVPy6uI0u7sJU8fNDEiMWe3QrFUUqWUICQslLDIXUdXKctpbp6v0/Bentx3g934Xvht8aOYqitWrACQv5wiNCOeP6FN+j/3vfKnbOd2l7sIxBShhjNkObAQ2ALOA10i++nxTBs+zyxhTwFp7ylr7wp8bjTGlgLMXOc4vBg35kvoNbqVo0cL8tvVnPvn4SyIikv9qBg0cQatWd/F828dJSEwk7lwczz7dMeXYvHkjaXJbff7d8d30Xj5H+m5wT+p5c95ol/Bpl79yHjxwJC3vv4tn2z5GYkIC587F8/wzf739kzdvJI2b1ONVh+Xcre9H1KxbjagiUcxbM4VvuvUnPDw55x+HTqD5vbfx8NNtSExMJC4unv+0S85vw6+bmD31J8bMGUpiYiK/bdjKmGETA5hJxt307b8pVPdmIooU4NZf+7K724+ERIQBcHDoHM5t28+J+WupPr8HJCVxaPg8zm7ZS8FaN1H8wUac3rybanOT3yLd2XUEJ+atCWQ6F8iuGQpjTG+SJwtKAHONMdHW2puNMdOB9621q4BRQA1gM5BEcl0c6H2JPkAk0M+YlNm9J621G7Il4CDRd2AP6tavSZGihVmzeQHdun5FuLdmDR00mntb3sHTzz9CYkIicXFxtHsu+W46v65ez9RJs5mzaDyJCQlsWP8bw4aMBqB3zwH0GdCNdh2e4cyZs7z2Ss6qacGYc4++H1OzXnUKF4liwdqpfPV5/5ScR38/njvuuY1HnnmAxMQE4s7F83q7d1KO7T3oM6IKFyIhIYEP//s5p04mX5jXtEVj3v3kPxQpWpi+I3qyZeNW2j7cMc3zB0K1b1+haN3y5CpSgKa/fo3tNpZQb867h87l9LYDHJ2/jkbzP8OT5GHP8Pmc2rKPIrUM1zzYkJOb99BwblcAtnQdzZF5a9kzcj5Ve7an0YLP8fyRwJqO314sBL9xwsxyRoV4LrFS23uRTSWS1/v9+f+KJP+CsB5Yb619KTMnN8bkA/JZa4/4clzBfGWc8MtJlgoLyfET9Vnqqnw5fmVPlvs25NpAh+B3DQ+NyXQ1/bnEAxmuA/UOjXVP1Xag4oVuCrqaHYwK5w78EgF/6xZaNtAh+NW9h0ZeVi11U92+5H2gvW9xLuZv90Q1xlzPX011plhrzwBnMnu8iAQvd1weJCISPNxUtzP9QSrW2j+vYp+UdeGIiGRMooveChQRCQZuqtv6JEIRcaQk3FOIRUSCgZvqthpoEXEkj4sKsYhIMHBT3VYDLSKO5Ka1dCIiwcBNdVsNtIg4kptmMkREgoGb6rYaaBFxJDfNZIiIBAM31W010CLiSIkumskQEQkGbqrbaqBFxJGS3FOHRUSCgpvqthpoEXEkN90OSUQkGLipbquBFhFH0mdDi4g4i5vqthpoEXEkN12MIiISDNxUt9VAi4gjJYa4561AEZFg4Ka6rQZaRBzJTTMZIiLBwE11Ww20iDiSm67mFhEJBm6q22qgRcSR3HQ1t4hIMHBT3VYDLSKO5KaruUVEgoGb6rYjG+iz5+MDHYLfued3tow5GHI80CH43ayiNwQ6BL9reBnHuumtQLc7fT4u0CGIH4SHhgU6BL9bUzA00CH41b2XeXx21G1jTHegDVAaqGSt3ZjOfg8B75HcUnmAptbaw8aY94BHgETgPPC2tXbWpc4bXF95EXGNRB8eIiISeNlUtyeSPB+zO70djDE1gM5AM2ttRaA+EOsdXgHUtNZWBp4DRhtjIi91UkfOQIuIaAZaRMRZsqNuW2uXABhjLrbbq0B3a+0h7zF/Ns/8bbZ5Pckz1EWBfRd7QTXQIuJIbrodkohIMPClbhtjooCoNIZirLUxPp66ArDTGLMIyA+MB7pYa/++LPspYIe19qLNM2gJh4g4VJIPDxERCTwf63YnYGcaj06ZOHUYUBloBjQC7gKeTL2DMaYR8BHwaEZeUDPQIuJIHi3hEBFxFB/rdi9gSBrbYzJx6j3AWGttPBBvjJkE1AKGAhhj6gA/AC2ttTYjL6gGWkQcSTPLIiLO4kvd9i7TiMmiU48AWhhjhpHc+94OjAUwxtQERgMPWGt/zegLagmHiDiS7sIhIuIs2VG3jTG9jTH7gFLAXGPMJu/26d67bwCMAo4Am4G1wCZgoHesDxAJ9DPGrPU+Kl3qvJqBFhFH0l04REScJZvuwtER6JjG9hapnicBr3kff9+vZmbOqwZaRBxJSzhERJzFTXVbDbSIOJKbCrGISDBwU91WAy0ijvT3m3eKiEjO5qa6rQZaRBwpQWugRUQcxU11Ww20iDiSm2YyRESCgZvqthpoEXGkJFeVYhER93NT3VYDLSKO5KaLUUREgoGb6rYaaBFxpOyaxzDGdAfaAKWBStbajens9xDwHhDiDaeptfawMSYM6A3c6d3+qbX2u2wKV0TEMdwz/6xPIgRgQP8eHNi3jrVr5qU53qhhHaKP/saqlbNZtXI2777TCYBy5W5I2bZq5WyOH9tCx1fa+jHyzBvQvwf7961jTTo5N2xYh2Opcn4nnZyjHZTzV326Yn9fzs+/TEtzvF79Wuza9ysLf57Mwp8n88ZbLwNQ9sbrU7Yt/Hkyu/evoX2HZ/wYeea1/vxf/N+qb+k467N097m+dnlenv4JHWd/TtvR76Vsv7FRZTrN685rC76g4Yv3+iNcnyT58PDRRKAhsDu9HbyfbtUZaGatrQjUB2K9w48DZYEbgTpAZ2NMad/DkNS+7fs5u3atYuXKWWmON2hQmwMH17Ns+XSWLZ/Of//vr89VePnl51m5ajYrV85iyJDe5M6dG4A+337G8uUz+OWXGfwwvA/58uX1Sy4ZFYw59/jqI9ZtXcS8pRPTHK9Trya/7V7O7EXjmL1oHJ3eeDFl7IUXn+KnpZOYt3Qi33zXjdy5cwEwfvrQlP1Xb57PwB96+yOVDLu32wu8vroP7Wd/mu4+19Uuz7+mf0L7OZ/x9Oh3M3xs7Rda8P7u4UQWzp/lcWdGNtZtv9MMNDB06I/06TOYwYO/THefJUtW0PL+py/YtnXrDmrUbA5AaGgoe3atZuKkGdkaa1b53pvzoEvk3OoSOe92UM4jho9nQL9hfNu/W7r7LFu2ikcf/NcF27Zv20mjevcByTlv2rqEqVNmZ2usWeXXsYtY/v1sHvjixTTH8xTMy30fPcuQpz8j9kA0+YoWBCAkNIR7P3yWwU905eShaF6c/DG/zfmVo9v3+zP8i0oIyZ65DGvtEgBjzMV2exXobq095D0mNtXYw8AA7ydfHTXGTAQeBNL/xpNL+mHYWPr1/Z4BA75Id5+lS1fyQJvnL9hW8qrivNjhGapXa0pcXDxDh33Ngw/eyw8/jOWtNz/i1KnTAHz66bu0b/80PXp8m615+CIYc/5x5EQGDxjBl327prvPimWrefqRly7YVqLklTzX7nGa1L6PuLh4+g7qQcvWLfhx5ERat3gqZb/+3/di9vSfsi3+zFg3ZjErv59Dqy/apzmeu2BeWnz8LMOf+oyTB6LJ663Tlzq2YMki3NCgEjH7jmVb7L7KrrodCGqggcVLfuG660pd1mvcflt9fv99N3v25JwG42KWZEHOtzks52U/r+Saa6++rNdo1Lguu3buYd/eA1kUVfbatWILUaWKpTte5b66bJq5ktgD0QCciT4JQKmqZTm++zAn9h4BYP2UZZRvXj1HNdC+lGFjTBQQlcZQjLU2JhOnrwDsNMYsAvID44Eu1loPcC0Xzl7vAa7JxDkklZ9/XsG112auZoWHhxEZmYfz5xPImzeSgwcPA6Q0kgB5IvPg8eSsH+7BmPMvS1dT6pqrMnVseHgYefIk5xyZNw+HDh25YDx/gXzUa1iL115+JytCzTJ7Vmyh0EXqdKWWddkycyUnvXX6rLdOX+rY5u8/ydyuI3l4wD8+vTpgctZ32+XREo4Mql27OqtXzWHq5GFUqFDuH+MPPdSSUaMn+j+wbPRnzlPSyfnhh1oy2mU516xVlUVLJ/PjuO+46aay/xhv/cDdjBszNQCRZY+iZUoSWSgfz496lw5TulC1dQMAChYvnNJUA5w8eJxCxYsEKsw0+fhWYCdgZxqPTpk8fRhQGWgGNALuAp7M5GtJFqlVqxrLl89gwsQhlC9/IwAHDxzmy14D2GKXsuP3FZyMPcW8eYtTjunbrxs7d66kXLkb+PbbIQGKPPOCMefqNasyZ/F4ho3pS7mbbgDg0MEj9P1qCCs2zGXNlgWcPHmaRfOXXnDcnS1u5+eFv3D61JlAhJ1pRa4vQZ5C+Xhq1Du0nfoxlVvXv+Qx5ZpV59Sh4xz+bY8fIsw4Ny3h8EsDbYxplup5IWPMMGPMDmPMOGNMcX/EcDl+XbOBMmVrUb1GM77pM5hxYwZdMB4REcG99zRn7Dj3NFZr1mzghlQ5j00j53tclvP6dZupUqExDeveR/9+wxg28sK3NSMiIrizxW1MmuCMJSsZERYWxlWVrmfos90Y8tSnNHnlfopeXyLQYWVIEp4MP4BewPVpPHpl8vR7gLHW2nhr7SlgElAr1dh1qfa9FtibyfNIBq1du5HyN9Wjdu276PvtEEaN7g9AVFRB7rmnGTdXaEDZG24lb768PPJIq5Tj2rd7gxtuuBVrt/PAAzlvrf/FBGPOG9ZvplblZjRr0JrB/Ycz6IevAChUqCB3tLiN2lWbU618E/LmjaT1Q/dccGzLB1owcdz0QIR9WULDwyhZ8XpGPtud4U9+SoOO91PkInU6PE8uGrx0Hwu+GOvHKDPGx7qdo/lrBjr1FUxdgFNAS2ALyVer52inTp3mzJmzAMyY+RMREeEULVo4ZfzOO5uwZs0GjhzJOeuMLlfqnGcGYc5zZy8kIiKcIqlybtq8IevXbubo0ej0XsJxYg9Fs33Res6fi+fsiVPsWvEbJctfx8nDJyh0VdGU/QqWLELs4eMBjPSfPD48rLUx1tpdaTxiMnn6EUBzY0yIMSYCuB1Y5x0bA7xgjAk1xlwBtAJy3k8yl0n973fWrAVERERQtGhhmjSpz67dezl27DgJCQlMnjSTW2tXv+DYpKQkxo6ZQstWdwYi9EwLxpxPnzrDWW/OP81ZTHhEOIWLRNGgcW327N7H8egTJCQkMGPKXGrUuiXluMJForilWiXmzV4YqNAz7dTB4+zw1ulzJ06zZ8UWipe/Nt39i1xXnKhrrqDdjK50XNKLgiWL8K9pXch3RSE/Rp02X+p2TuevBjr1hzfWB/5trd1orX2H5LWEOVrx4lekPK9ZoyqhoaFER59I2fbIw61ct3zjUjk//HAr1y3fuPLKv9aRVatemdDQUI6nyrnNA/cwbqx7ZtwBfpu9mutqGELDQonIk4trqpblyPb97F+3g6KlS1C41BWERYRR+d46bJmzOtDhXiABT4YfvjDG9DbG7ANKAXONMZu826d7774BMAo4AmwG1gKbgIHesWHA78A2YDnwobV252WmK5eQumZVr1GF0NAQoqNPsHffAWrWvIXIyDwANG5cD7tlOwBlyvz1RsHddzdlq93h36AvUzDmfEWqOl21WiVCQ0M5cTyG/fsOUq1GFfJ4c67fqDbbUuV2T8vmzJ21kPj4P/we8+Wyc1Zzbc1yhISFEp4nF1dXvYFj29O/DueI3UuP6h3oXb8Tvet34uTB4/S/+x3OHI1N9xh/ya66HQj+uogwtzGmPN77pVprz6caS/RTDOn6Ydg3NGpYh2LFirDr91X878PuREREANB/wDDatL6bdu2eIiEhkbhzcTz+RIeUY/PmjaTp7Q15scNbgQo/U4alynnn76v4MI2c/9XuKRITEjl3Lo4n0si5g8NyHjCoJ/Ua1KJo0cJs3LKYTz/5kvDw5JyHDBrJfa3u5Lm2j5GQkEBcXDxtn+2UcmzevJE0vq0er/77vXRePWd6qPfLlKldnryFC/Dmsq+Y13McYRFhAKwYPo+jOw6wdeF6Xpn5KZ4kD6tGz+fI1n0ATHl/CM8M/S8hYaH8+uMCjmzLORcQQvbNUFhrOwId09jeItXzJOA17+Pv+yUCad/2RDJtyJDeNGhYm6JFC7N12zI+/rhnSs0a+N1wWt1/F23bPpFcs+LiePqpVwBYtXItEyfO4Oel00hMSGDduk0MGjSSkJAQ+g/oQcEC+QkJCWHDht/497/fvVgIfheMOX/zXTfq1KtJkaJRrNo4j+6ffkNERHKrMmzwj9zdsjlPPfswiYnJP487PP8fANas3sC0ybOZtWAMCYmJbFr/G8O/H5Pyuve1votveg1M85yB1rr3S1xXJ7lOd1r+FQt6jiUsPDnn1cPncWz7AbYvXE/7WZ/iSUpizagFHPXW6bSOXTs6586y5/y2OONC/HEFrjFmF8lrwv+cia5vrd1vjCkILLDWVvPl9cJzXe2mr0GGhFx6F1cpkDtn3ZvUH14sWjPQIfhdl10jMv2t/e/Sj2S4Dny5a1Sw/RPKUfLlLR10NTsYReXOF+gQ/K5dwaqBDsGv3t89/LJqqZvqtl9moK21pdMZSiD5E79ERHzicdVchoiI+7mpbgf0PtDW2rMk30pKRMQnTrjNkYiI/MVNdVsfpCIijuSE2xyJiMhf3FS31UCLiCMluqgQi4gEAzfVbTXQIuJIbnorUEQkGLipbquBFhFHctPFKCIiwcBNdVsNtIg4kptmMkREgoGb6rYaaBFxJDfNZIiIBAM31W010CLiSG6ayRARCQZuqttqoEXEkRL98CmqIiKSddxUt9VAi4gjuel+oiIiwcBNdVsNtIg4kpvW0omIBAM31W010CLiSG5aSyciEgzcVLfVQIuII7nprUARkWDgprqtBlpEHMlNHwkrIhIM3FS31UCLiCN5XHQ1t4hIMHBT3VYDLSKO5Ka3AkVEgkF21G1jTHegDVAaqGSt3ZjOfg8B7wEhgAdoaq09bIwJA3oDd3q3f2qt/e5S5w3NmvBFRPwryYeHiIgEXjbV7YlAQ2B3ejsYY2oAnYFm1tqKQH0g1jv8OFAWuBGoA3Q2xpS+1EkdOQNdPF9UoEPwu0RPcLUBIYQEOgS/O68ZVZ+46XZIbhefcD7QIYgf/BGREOgQ/C64fjJfvuyo29baJQDGmIvt9irQ3Vp7yHtMbKqxh4EB1tok4KgxZiLwINDtYi/oyAZaRERLOEREnMWXum2MiQKi0hiKsdbG+HjqCsBOY8wiID8wHuhirfUA13Lh7PUe4JpLvaAaaBFxJDd9JKyISDDwsW53Aj5IY/v/SF6O4YswoDLQDMgFzCS5UR7q4+ukUAMtIo6kJRwiIs7iY93uBQxJY3tMJk69BxhrrY0H4o0xk4BaJDfQe4DrgJXeff8+I50mNdAi4khawiEi4iy+1G3vMo2YLDr1CKCFMWYYyb3v7cBY79gY4AVjzHigKNAKaHCpF9RdOETEkTweT4YfIiISeNlRt40xvY0x+4BSwFxjzCbv9uneu28AjAKOAJuBtcAmYKB3bBjwO7ANWA58aK3deanzagZaRBxJM9AiIs6SHXXbWtsR6JjG9hapnicBr3kff98vEXjR1/OqgRYRR9IaaBERZ3FT3VYDLSKOpLtwiIg4i5vqthpoEXEkLeEQEXEWN9VtNdAi4khuKsQiIsHATXVbDbSIOJLuriEi4ixuqttqoEXEkdw0kyEiEgzcVLfVQIuIIyV5kgIdgoiI+MBNdVsNtIg4UnbNZBhjugNtgNJAJWvtxjT26Qx0AA54N/1srX3JO1YO6A9EAbmB0dbaztkSrIiIg2gGWkQkwLJxLd1E4Etg8SX2G2qt/U8a2z8HxlprvzbG5Ac2GWOmW2tXZHGcIiKOojXQIiIBll0zGdbaJQDGmMy+hAco5H2e1/vnI5cfmYiIs7lpBjo00AHkBD2++oh1Wxcxb+nENMfr1KvJb7uXM3vROGYvGkenN5I/8fGGsqVTts1eNI4tu3+hbfsn/Rh55vX8+mM2blvCgqWT0xyvW78mW3evYO7i8cxdPJ7X3uwAJOf857a5i8ezbc9KXnjxKX+GnmlffP0xG7YtZv7SSWmO16lfE7v7F+YsHs+cxeN59c2/vs5/bpuzeDxb96zghRed8XV+8PN2vL+qL6/N+jzdfcrULk+n6V15bXY32o9+P2V7uUZVeGNeD95c0JPGL97nj3B94vHhP2NMlDGmdBqPqMsI4RFjzHpjzGxjTJ1U2zsBDxtj9gO7gG7W2l2XcR4BBvTvwYF961i7Zl6a440a1iH66G+sWjmbVStn8+47nVLG/t3xBdat/Ym1a+bxw7BvyJ07NwClS1/D0iVT2LJ5CSOGf0tERIQ/UsmwYMz5y68/YfP2pSxaNiXN8br1a7FjzyrmL57I/MUTef3Nl1LG2nV4msXLp7Jo2RT6DexB7ty5Usbefq8Ty1fP5OcV03mhXc6q3y27vcAbq/vQYfan6e5TunZ52k//hA5zPuOZ0e9m+Ng6L7Sg8+7h5C2cP8vjzgxf6nZOpwYa+HHkRB5/oN1F91mxbDXNG7ahecM29Or2LQA7tu9K2XZn4wc5dy6OGdPm+iPkyzZ6xEQefeBfF93nl2WradqgNU0btOaLz/sAyTn/ua15owc4d+4cM6Y6I+cfR0zgsQzk3KxBa5o1aE3Pz//6Ov+57Y5GDyR/naem/QMtp1k1diEDn06/KOcpmJf7P3qOIW2780XzNxjWoRcAIaEh3P/hswx85jN6NPsPVe+ry5Vlr/ZT1BmT5PFk+EFyU7szjUenTJ6+L3C9tbYy0A2YZIwp6h1rBwyz1l4N3AB0NMbcmtk8JdnQoT9y9z2PX3SfJUtWUKNmc2rUbM7HXXoBcNVVJXj5pee4tXYLqt5yO2FhYTz8UEsAun7yDr16D+CmCvU5cSKW5559NLvT8Ekw5jxqxHgeadP2ovssX7aKJg1a0aRBK3p8/g0AJUpeyQvtn6JZ4zY0rHMvYWFh3N/mbgAefbw1V11dkjo17qJerRZMGDct2/Pwxdoxi/nh6fQnOfIUzMvdHz/LyLY96NPsLcZ06J2hYwuWLMINDSoRs+9YlsecWT7W7RwtIA20MSa/MaaaMaZgIM7/d78sXU3MidjLeo36jWqze9de9u89mEVRZa/lS1cRcyLmsl6jQaPa7Nq5l317D1x65xxg+dLVnLjMr3Nyznsck/POFVs4G3s63fFb7qvHxpkriTkQDcCZ6JMAXFO1LMd2H+L43iMknk9k3ZRl3Ny8hl9izqhET1KGH0Av4Po0Hr0yc25r7SFr7Xnv8znAXqCid7gj8L137CDwE9Aws3lKssVLfuF4JmtWeHg4kZF5CAsLI29kJAcPHgKgSeN6jPM2U8OGjaHlfXdkVbhZIhhzXrZ0VabrdHhYGHm8OUdG5uHQoeSVU888/yg9Pv8mZf3tsWPHsyzerLB7xRbOxaRfpyu1rMtvM1cS+7c6falj73z/SeZ0HQk5qBn1sW7naH5poI0xfY0xV3if1wN2AMOA7caY5v6I4XJVr1mVOYvHM2xMX8rddMM/xlu2vouJ46YHILLsU71WVeYtmcCIMf0wN5X9x3irNi2YmMN+k79c1WtVZe6S8Qwf049yaeTcsk0LV32di5UpSWShfLQb9R4dp3ShWusGABQqXjilWAPEHoymYPHCgQozTb68FWitjbHW7krjEZOZcxtjrk71vCrJd+yw3k07gTu9YwWABsA/7uQhWa927eqsXjWHqZOHUaFCOQAOHDjEFz37snPHCvbtWUPsyZPMmbuIokULExMTS2JiIgD79h/kqqtLBDL8TAnGnGvUqsr8JZMYNXZAys+mQweP0OerQazdOJ+NW5dw8uRpFvz0MwClr7+GVq1bMGfBOEaNHUCZMtcFMnyfFb2+BHkK5eOZUe/wr6kfU6V1/UseY5pV5+Sh4xz+bY8fIsw4LeHwXR1r7VHv84+Ae621NwP1gU/8FEOmbVi/mVqVm9GsQWsG9x/OoB++umA8IiKC5nc1YerEWQGKMOutX7eZGpVu5/b69zOw/3AGD//6gvHknG9jsoty3rBuMzUrNaVp/dbenP/5db7jriZMcVHOoWGhXF3pegY9+znfPfUpTV+5n2LXO+MHana9FWiM6W2M2QeUAuYaYzZ5t083xvw5Df+JMWajMWYdMAB40lp7yDv2DNDeO/YL8KO1dkYWpCwX8euaDZQpW4vqNZrxTZ/BjBszCICoqELcd+8dlC1Xm2uuq0a+fHl57LHWAY42awRjzuvXbaJaxdtoUr8l3/UbxtARyUs4CkUV5M67b6d65dupZBqQN28kDzyUfO1G7ly5iIuLp1njNgz7/ke+/CbHtx0XCA0P46qK1zP82e788OSnNOx4P0UvUqcj8uSiwUv3Mf+LsX6MMmO0hMN3kameF/jzdk7W2q1ArrQPyTlOnzrD2TNnAfhpzmLCI8IpXCQqZbxJ0/psWLeZY0ej03kF50md87w5i4iICKdIqpxva9bA1Tn/FCQ5xx46ztZF6zl/Lp6zJ07x+4otlCx/HbGHT1DoqqIp+xUqWZSTh08EMNJ/yq6ZDGttR2ttKWttuLW2hPeXfay1Lay1q7zPn7bWVrTWVrHW1rTWTk91/GprbV3vWAVr7YdZmrik6dSp05zx/vudMfMnIiLCKVq0MLff3oCdu/Zw7NhxEhISmDBxBnVq1yA6+gRRUYUICwsDoNTVJTmw/9DFTpHjBGPOp0+dScl57pxFhIeHU6RIYRo1rsue3fuIjj5BQkIC06bMpuattwBw4MBhpk2ZA8C0KXOocHOm77ATECcPHmd7Sp0+ze4VWyhe/tp09y98XXEKX3MFL87oSqclvShYsgjtpnUh/xWF0j3GXzQD7bu5xpgexpi8wHxjzMMAxphmQI7vRq64sljK86rVKhEaGsqJ4zEp21o94K639eHCnG+pVomQkBCOp8r5/jZ3u275xj++ziGhF+Tcqk0LJrjs67x59ipK1zCEhoUSkScX11Yty5Ht+9m3bgfFSpegcKkrCIsIo8q9ddg8Z3Wgw72Am2Yy5PIVL35FyvOaNaoSGhpKdPQJ9u7Zz623ViMyMg8AtzWpz5Yt2wBYsHApbbwXmj355INMnjLb/4FfhmDM+cq//WwKDQ3l+PET7Nt7gOo1qqTk3LBRHbbZHQDMmDaX+g2Sr+OtW78WO3bs8nvcl2PLnNVcW7NcSp0uVfUGjm1P/zqcI3Yv3ap3oFf9TvSq34mTB4/T7+53OH308q4Bygpuqtv+ug/0qyRfqb6f5Ib5P8aYocB84Dk/xZCub77rRp16NSlSNIpVG+fR/dNviIhI/qsZNvhH7m7ZnKeefZjExETizsXR4fm/PjshMm8kDRvX5a1X/xeo8DPl2++6U7d+LYoUjeLXTfPp9unXRIQn5zx08Gjubdmcp597lITEBOLOxdP++ddTjs2bN5KGTeryxqsfBCr8TOnzXbeUnFdv+onun35NRHjyLZyGDh7NPS2b8/Rzj6SZc6Q35zdf7Ryg6DPnsd6vUKZ2efIVLsDby75mTs+xhHm/t5cPn8uRHQfYunAdr878DE+ShxWj53N46z4AJr0/hLZD/4/QsFBW/riAw9v2BTKVf3DCDIVknR+GfUOjhnUoVqwIu35fxf8+7J5yC7b+A4bRpvXdtGv3FAkJyXX68SeSb725YuUaxo+fxsoVs0hISGDt2k0M+G44AP/3dhdG/NCHDzu/ydp1mxg0eGTA8ktLMObcb2AP6tWvRZGihVm3eSGfd/2KcG/N+n7QKO5teQfPPP9ocs5xcfzrudcA+HX1eqZMmsW8RRNISEhgw/rfGDpkNABf9uxP3wHdadfhac6cOcurr7wTsPzS0qb3S5SuU568hQvw2vKvmN9zLGHen8erhs/j2PYDbF+4nhdnfYonKYlfRy3giLdOp3XsmtELA5nORbmpbof481NhjDH5SL6tUxiwx1qbqdnnqwvf7J6vQAY54YrUrBRCSKBD8Lsno6oEOgS/+3zXyEx/oa8rWjnDdWB39Prg+4bKQcJzXR10NTsYFY7MGfca9qeXonLW3YmyW+fdwy+rlrqpbvv1kwittWeA9f48p4i4k5s+ElZEJBi4qW7ro7xFxJHc9JGwIiLBwE11Ww20iDiSm2YyRESCgZvqthpoEXEkJ1ylLSIif3FT3VYDLSKOlBRkF9aKiDidm+q2GmgRcSQ3raUTEQkGbqrbaqBFxJHctJZORCQYuKluq4EWEUdy01o6EZFg4Ka6rQZaRBzJTTMZIiLBwE11Ww20iDiSm9bSiYgEAzfVbTXQIuJIiUnuuZpbRCQYuKluq4EWEUfyuGgmQ0QkGLipbquBFhFHctPFKCIiwcBNdVsNtIg4kpsuRhERCQZuqttqoEXEkdz0VqCISDBwU91WAy0ijuSmmQwRkWDgprqtBlpEHMlNa+lERIKBm+p2iJt+GxARERERyW6hgQ5ARERERMRJ1ECLiIiIiPhADbSIiIiIiA/UQIuIiIiI+EANtIiIiIiID9RAi4iIiIj4QA20iIiIiIgP1ECLiIiIiPhADbSIiIiIiA/0Ud5/Y4wpB3wPFAWigaestdv+tk8Y0Bu4E/AAn1prv/N3rL643LwuMdYc+ASoBHxlrf2PX5LyQRbkn+NzvJQM/h04Pk8JLqrZ7qzZoLqtmp2zaQb6n/oC31hrywHfAP3S2OdxoCxwI1AH6GyMKe23CDPncvO62NjvQFugW3YFnwUuN38n5HgpGfk7cEOeElxUs91Zs0F1WzU7B1MDnYox5kqgGjDSu2kkUM0Yc8Xfdn0YGGCtTbLWHgUmAg/6LVAfZVFe6Y5Za7dba9cCCdmZR2ZlRf45PcdLyejfgdPzlOCimu3Omg2q26rZOZ8a6AtdA+y31iYCeP9/wLs9tWuB3an+vCeNfXKSrMjLaTmn5tavqy8y+ncg4iRu/bcd7DUb3Pu1zSjV7BxODbSIiIiIiA/UQF9oL3C196KEPy9OuMq7PbU9wHWp/nxtGvvkJFmRl9NyTs2tX1dfZPTvQMRJ3PpvO9hrNrj3a5tRqtk5nBroVKy1R4C1wKPeTY8Ca7zrqlIbA7xgjAn1rkdqBYz1V5y+yqK8HJVzam79uvrCh78DEcdw67/tYK/Z4N6vbUapZud8uo3dP7UHvjfGvA+cAJ4CMMZMB9631q4ChgG3An/eTuZDa+3OQATrg8vNK90xY0x9YBRQEAgxxjwCPG+tnZX9aWXYZeXvkBwv5ZJ/By7JU4KLarY7azaobqtm52AhHo8n0DGIiIiIiDiGlnCIiIiIiPhADbSIiIiIiA/UQIuIiIiI+EANtIiIiIiID9RAi4iIiIj4QA20iIiIiIgPdB9oyTGMMb8BBYA7rLWbAh2PiIikTzVbgplmoCUnqQhsBR4IdCAiInJJqtkStNRAS45hrU0ElgCVAx2LiIhcnGq2BDMt4ZAcwxgTCTwKhAQ6FhERuTjVbAlmmoGWnKQLsA8oY4zJ/+dGY8x4Y0y5wIUlIiJpUM2WoKUGWnIEY0wd4EGgDRALVEo1fAOwIxBxiYjIP6lmS7BTAy0BZ4zJAwwG2ltrjwPr8K6p844leNfaiYhIgKlmi6iBlpzhQ2CptXaa989rgSre5zcBWwIRlIiIpEk1W4KeLiKUgDLG1CL5bcCqqTavBdp6n1cENvs3KhERSYtqtkiyEI/HE+gYRNJljOkK/GKtnRjoWERE5OJUsyVYqIGWHM0YMxkoAZz0bnrQWnsigCGJiEg6VLMlWKiBFhERERHxgS4iFBERERHxgRpoEREREREfqIEWEREREfGBGmgRERERER+ogRYRERER8YEaaBERERERH6iBFhERERHxgRpoEREREREfqIEWEREREfHB/wPvjJVCtziVUgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(12, 4), sharey=True)\n",
    "pt_dependent = pd.pivot_table(strat_results_df[strat_results_df['loss type']=='train'], values='loss', index='length k', columns='length reg')\n",
    "sns.heatmap(pt_dependent, annot=True, fmt='.2f', ax=ax[0]).set(title='train', ylabel=r'$k$', xlabel=r'$\\lambda_L$')\n",
    "\n",
    "pt_dependent = pd.pivot_table(strat_results_df[strat_results_df['loss type']=='val'], values='loss', index='length k', columns='length reg')\n",
    "sns.heatmap(pt_dependent, annot=True, fmt='.3f', ax=ax[1]).set(title='val', ylabel='', xlabel=r'$\\lambda_L$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25e260d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Stratified augmented model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5855f0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnl_strat_sweep(i, mnl_k, rank_reg):\n",
    "    result=[]\n",
    "    val = folds[i]\n",
    "    train = pd.concat([df for j, df in enumerate(folds) if j!=i])\n",
    "\n",
    "    train_choices, train_agent_codex, train_alt_codex, train_ballot = dp.prep_dataset(train)\n",
    "    (xval, xlval, yval), val_agent_codex = dp.prep_valset(val, train_alt_codex)\n",
    "\n",
    "    kwargs={'mnl_fixed_effects': True,\n",
    "            'position_dependent_end': False,\n",
    "            'mnl_k': mnl_k,\n",
    "            'rank_reg': rank_reg\n",
    "           }\n",
    "    model, tr_loss, no_params, num_epochs, runtime, tr_losses, _ = sp.train(ds=train_choices, \n",
    "                                                                            num_items=len(train_alt_codex), \n",
    "                                                                            alternative_codex=train_alt_codex, \n",
    "                                                                            epochs=2000, \n",
    "                                                                            lr=1e-3, \n",
    "                                                                            wd=1e-5, \n",
    "                                                                            verbose=True, \n",
    "                                                                            Model=sp.ENDModel,\n",
    "                                                                            **kwargs)\n",
    "    task_loss = tr_loss - np.array(tr_losses)[-1, -1]\n",
    "    result.append(['stratified augmented', i, mnl_k, rank_reg, 'train', task_loss, num_epochs, runtime, no_params])\n",
    "    result.append(['stratified augmented', i, mnl_k, rank_reg, 'train + reg', tr_loss, num_epochs, runtime, no_params])\n",
    "    \n",
    "    yval_hat = model.forward(xval, xlval)\n",
    "    v_loss, v_loss_terms = model.loss_func(yval_hat, yval, xval, xlval, train=False)\n",
    "    result.append(['stratified augmented', i, mnl_k, rank_reg, 'val', float(v_loss), num_epochs, runtime, no_params])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ba10560e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "mnl_ks = [1,2,3,5,10,15]\n",
    "rank_regs = [0.0, 1e-3, 1e-2, 0.1]\n",
    "\n",
    "aug_strat_results = Parallel(n_jobs=30)(delayed(mnl_strat_sweep)(i, mnl_k, rank_reg) \n",
    "                                        for i in range(kfolds)\n",
    "                                        for mnl_k in mnl_ks\n",
    "                                        for rank_reg in rank_regs)\n",
    "aug_strat_results = [item for sublist in aug_strat_results for item in sublist]\n",
    "aug_strat_results_df = pd.DataFrame(aug_strat_results, columns=['model', 'fold', 'mnl k', 'rank reg', 'loss type', 'loss', 'num epochs', 'runtime', 'no params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5f07ffb9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation fmin which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [36]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m4\u001b[39m), sharey\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m pt_dependent \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mpivot_table(aug_strat_results_df[aug_strat_results_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss type\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m], values\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmnl k\u001b[39m\u001b[38;5;124m'\u001b[39m, columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrank reg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43msns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheatmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpt_dependent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.2f\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43max\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mset(title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, ylabel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m$k$\u001b[39m\u001b[38;5;124m'\u001b[39m, xlabel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mlambda_L$\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m pt_dependent \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mpivot_table(aug_strat_results_df[aug_strat_results_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss type\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m], values\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmnl k\u001b[39m\u001b[38;5;124m'\u001b[39m, columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrank reg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(pt_dependent, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;124m'\u001b[39m, ax\u001b[38;5;241m=\u001b[39max[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mset(title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m, ylabel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, xlabel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mlambda_L$\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/seaborn/_decorators.py:46\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPass the following variable\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m as \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124mkeyword arg\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrom version 0.12, the only valid positional argument \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     )\n\u001b[1;32m     45\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate({k: arg \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args)})\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/seaborn/matrix.py:540\u001b[0m, in \u001b[0;36mheatmap\u001b[0;34m(data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, linewidths, linecolor, cbar, cbar_kws, cbar_ax, square, xticklabels, yticklabels, mask, ax, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;124;03m\"\"\"Plot rectangular data as a color-encoded matrix.\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03mThis is an Axes-level function and will draw the heatmap into the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;124;03m    ...     ax = sns.heatmap(corr, mask=mask, vmax=.3, square=True)\u001b[39;00m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;66;03m# Initialize the plotter object\u001b[39;00m\n\u001b[0;32m--> 540\u001b[0m plotter \u001b[38;5;241m=\u001b[39m \u001b[43m_HeatMapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvmax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrobust\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mannot_kws\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbar_kws\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxticklabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m                      \u001b[49m\u001b[43myticklabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;66;03m# Add the pcolormesh kwargs here\u001b[39;00m\n\u001b[1;32m    545\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinewidths\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m linewidths\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/seaborn/matrix.py:159\u001b[0m, in \u001b[0;36m_HeatMapper.__init__\u001b[0;34m(self, data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, cbar, cbar_kws, xticklabels, yticklabels, mask)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mylabel \u001b[38;5;241m=\u001b[39m ylabel \u001b[38;5;28;01mif\u001b[39;00m ylabel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# Determine good default values for the colormapping\u001b[39;00m\n\u001b[0;32m--> 159\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_determine_cmap_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplot_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mcmap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrobust\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# Sort out the annotations\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m annot \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m annot \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/seaborn/matrix.py:198\u001b[0m, in \u001b[0;36m_HeatMapper._determine_cmap_params\u001b[0;34m(self, plot_data, vmin, vmax, cmap, center, robust)\u001b[0m\n\u001b[1;32m    196\u001b[0m         vmin \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnanpercentile(calc_data, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 198\u001b[0m         vmin \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcalc_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m vmax \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m robust:\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mnanmin\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/nanfunctions.py:343\u001b[0m, in \u001b[0;36mnanmin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m    338\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhere\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m where\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(a) \u001b[38;5;129;01mis\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;129;01mand\u001b[39;00m a\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mobject_:\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;66;03m# Fast, but not safe for subclasses of ndarray, or object arrays,\u001b[39;00m\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;66;03m# which do not implement isnan (gh-9009), or fmin correctly (gh-8975)\u001b[39;00m\n\u001b[0;32m--> 343\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfmin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(res)\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m    345\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll-NaN slice encountered\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m,\n\u001b[1;32m    346\u001b[0m                       stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation fmin which has no identity"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. params:  16\n",
      "Runtime: 35.3749623298645\n",
      "Loss: inf\n",
      "No. params:  16\n",
      "Runtime: 40.373024225234985\n",
      "Loss: inf\n",
      "No. params:  40\n",
      "Runtime: 58.327954053878784\n",
      "Loss: inf\n",
      "No. params:  80\n",
      "Runtime: 83.51190853118896\n",
      "Loss: inf\n",
      "No. params:  16\n",
      "Runtime: 55.470269203186035\n",
      "Loss: inf\n",
      "No. params:  120\n",
      "Runtime: 132.66855716705322\n",
      "Loss: inf\n",
      "No. params:  80\n",
      "Runtime: 91.96371269226074\n",
      "Loss: inf\n",
      "No. params:  16\n",
      "Runtime: 51.7606565952301\n",
      "Loss: inf\n",
      "No. params:  40\n",
      "Runtime: 64.5805492401123\n",
      "Loss: inf\n",
      "No. params:  80\n",
      "Runtime: 92.02272915840149\n",
      "Loss: inf\n",
      "No. params:  8\n",
      "Runtime: 21.28259301185608\n",
      "Loss: inf\n",
      "No. params:  8\n",
      "Runtime: 41.52172136306763\n",
      "Loss: inf\n",
      "No. params:  24\n",
      "Runtime: 59.55147981643677\n",
      "Loss: inf\n",
      "No. params:  40\n",
      "Runtime: 62.048142433166504\n",
      "Loss: inf\n",
      "No. params:  8\n",
      "Runtime: 27.339792728424072\n",
      "Loss: inf\n",
      "No. params:  16\n",
      "Runtime: 55.56663489341736\n",
      "Loss: inf\n",
      "No. params:  40\n",
      "Runtime: 73.37386846542358\n",
      "Loss: inf\n",
      "No. params:  8\n",
      "Runtime: 31.904754400253296\n",
      "Loss: inf\n",
      "No. params:  8\n",
      "Runtime: 27.079553604125977\n",
      "Loss: inf\n",
      "No. params:  80\n",
      "Runtime: 103.26490449905396\n",
      "Loss: inf\n",
      "No. params:  16\n",
      "Runtime: 48.62188768386841\n",
      "Loss: inf\n",
      "No. params:  16\n",
      "Runtime: 40.568851947784424\n",
      "Loss: inf\n",
      "No. params:  8\n",
      "Runtime: 20.773303747177124\n",
      "Loss: inf\n",
      "No. params:  24\n",
      "Runtime: 65.9624035358429\n",
      "Loss: inf\n",
      "No. params:  120\n",
      "Runtime: 123.96894216537476\n",
      "Loss: inf\n",
      "No. params:  24\n",
      "Runtime: 48.170581340789795\n",
      "Loss: inf\n",
      "No. params:  24\n",
      "Runtime: 39.499958753585815\n",
      "Loss: inf\n",
      "No. params:  8\n",
      "Runtime: 45.854095697402954\n",
      "Loss: inf\n",
      "No. params:  24\n",
      "Runtime: 60.57934784889221\n",
      "Loss: inf\n",
      "No. params:  80\n",
      "Runtime: 93.60053968429565\n",
      "Loss: inf\n",
      "No. params:  16\n",
      "Runtime: 32.459590911865234\n",
      "Loss: inf\n",
      "No. params:  80\n",
      "Runtime: 104.5580427646637\n",
      "Loss: inf\n",
      "No. params:  16\n",
      "Runtime: 50.059916257858276\n",
      "Loss: inf\n",
      "No. params:  16\n",
      "Runtime: 42.9030237197876\n",
      "Loss: inf\n",
      "No. params:  16\n",
      "Runtime: 33.7829372882843\n",
      "Loss: inf\n",
      "No. params:  8\n",
      "Runtime: 42.30574655532837\n",
      "Loss: inf\n",
      "No. params:  24\n",
      "Runtime: 60.19366502761841\n",
      "Loss: inf\n",
      "No. params:  80\n",
      "Runtime: 94.75053095817566\n",
      "Loss: inf\n",
      "No. params:  16\n",
      "Runtime: 34.164841175079346\n",
      "Loss: inf\n",
      "No. params:  8\n",
      "Runtime: 44.3631694316864\n",
      "Loss: inf\n",
      "No. params:  80\n",
      "Runtime: 104.970463514328\n",
      "Loss: inf\n",
      "No. params:  16\n",
      "Runtime: 41.797638177871704\n",
      "Loss: inf\n",
      "No. params:  16\n",
      "Runtime: 33.15793180465698\n",
      "Loss: inf\n",
      "No. params:  120\n",
      "Runtime: 114.4250328540802\n",
      "Loss: inf\n",
      "No. params:  16\n",
      "Runtime: 38.04075837135315\n",
      "Loss: inf\n",
      "No. params:  8\n",
      "Runtime: 29.6045880317688\n",
      "Loss: inf\n",
      "No. params:  120\n",
      "Runtime: 108.62085556983948\n",
      "Loss: inf\n",
      "No. params:  40\n",
      "Runtime: 75.7644875049591\n",
      "Loss: inf\n",
      "No. params:  8\n",
      "Runtime: 38.027713775634766\n",
      "Loss: inf\n",
      "No. params:  80\n",
      "Runtime: 95.73792934417725\n",
      "Loss: inf\n",
      "No. params:  24\n",
      "Runtime: 38.00601100921631\n",
      "Loss: inf\n",
      "No. params:  8\n",
      "Runtime: 44.61872339248657\n",
      "Loss: inf\n",
      "No. params:  80\n",
      "Runtime: 103.80960965156555\n",
      "Loss: inf\n",
      "No. params:  16\n",
      "Runtime: 44.830620765686035\n",
      "Loss: inf\n",
      "No. params:  24\n",
      "Runtime: 38.18913149833679\n",
      "Loss: inf\n",
      "No. params:  8\n",
      "Runtime: 43.10662651062012\n",
      "Loss: inf\n",
      "No. params:  24\n",
      "Runtime: 50.712270975112915\n",
      "Loss: inf\n",
      "No. params:  40\n",
      "Runtime: 60.627663135528564\n",
      "Loss: inf\n",
      "No. params:  120\n",
      "Runtime: 106.14816451072693\n",
      "Loss: inf\n"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(12, 4), sharey=True)\n",
    "pt_dependent = pd.pivot_table(aug_strat_results_df[aug_strat_results_df['loss type']=='train'], values='loss', index='mnl k', columns='rank reg')\n",
    "sns.heatmap(pt_dependent, annot=True, fmt='.2f', ax=ax[0]).set(title='train', ylabel=r'$k$', xlabel=r'$\\lambda_L$')\n",
    "\n",
    "pt_dependent = pd.pivot_table(aug_strat_results_df[aug_strat_results_df['loss type']=='val'], values='loss', index='mnl k', columns='rank reg')\n",
    "sns.heatmap(pt_dependent, annot=True, fmt='.3f', ax=ax[1]).set(title='val', ylabel='', xlabel=r'$\\lambda_L$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30c7c12",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "72e07339",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def kfold_train_test(i, model_name, length_k, length_reg, mnl_k, rank_reg, dataset_name, dataset, mnl_covariates=None, length_covariates=None, num_ranks=0):\n",
    "    if (model_name == 'conditionally independent') & ((mnl_covariates == None) | (length_covariates == None)):\n",
    "        return\n",
    "    \n",
    "    shuffled = dataset.sample(frac=1,random_state=0).reset_index(drop=True)\n",
    "    folds = np.array_split(shuffled, kfolds)\n",
    "    \n",
    "    result=[]\n",
    "    test = folds[i]\n",
    "    train = pd.concat([df for j, df in enumerate(folds) if j!=i])\n",
    "\n",
    "    train_choices, train_agent_codex, train_alt_codex, train_ballot = dp.prep_dataset(train)\n",
    "    num_observations = train_choices[0].shape[0]\n",
    "    num_agents = len(train_agent_codex)\n",
    "    num_alternatives = len(train_alt_codex)\n",
    "    max_length = train_ballot.length.max()\n",
    "    length_k = min(length_k, max_length)\n",
    "    mnl_k = min(mnl_k, max_length)\n",
    "        \n",
    "    (xtest, xltest, ytest), test_agent_codex = dp.prep_valset(test, train_alt_codex)\n",
    "    if mnl_covariates:\n",
    "        '''\n",
    "        RCV data has no covariates, so this condition is a placeholder. \n",
    "        If your dataset includes agent/alternative + agent covariates, \n",
    "           pass those along as mnl_covariates + length_covariates pandas dataframes.\n",
    "        '''\n",
    "        mnl_covariates_train = mnl_covariates.loc[train_agent_codex, train_alt_codex]\n",
    "        poisson_covariates_train = length_covariates.loc[train_agent_codex].values.astype(np.float32)\n",
    "        mnl_covariates_test = mnl_covariates.loc[test_agent_codex, train_alt_codex]\n",
    "        poisson_covariates_test = length_covariates.loc[test_agent_codex].values.astype(np.float32)\n",
    "    else: \n",
    "        mnl_covariates_train, poisson_covariates_train, mnl_covariates_test, poisson_covariates_test = None, None, None, None\n",
    "    \n",
    "    kwargs={'mnl_fixed_effects': True,\n",
    "            'max_length': max_length,\n",
    "            'mnl_covariates': mnl_covariates\n",
    "           }\n",
    "    if model_name == 'length dependent':\n",
    "        kwargs['categorical'] = True\n",
    "        kwargs['dependent'] = True\n",
    "        kwargs['length_k'] = length_k\n",
    "        kwargs['length_reg'] = length_reg\n",
    "    elif model_name == 'fully independent':\n",
    "        kwargs['categorical'] = True\n",
    "        kwargs['dependent'] = False\n",
    "    elif model_name == 'conditionally independent':\n",
    "        kwargs['dependent'] = False\n",
    "        kwargs['poisson_covariates'] = poisson_covariates_train\n",
    "    elif model_name == 'augmented':\n",
    "        kwargs['position_dependent_end'] = False\n",
    "    elif model_name == 'stratified augmented':\n",
    "        kwargs['position_dependent_end'] = False\n",
    "        kwargs['mnl_k'] = mnl_k\n",
    "        kwargs['rank_reg'] = rank_reg\n",
    "    else:\n",
    "        pass\n",
    "    model, tr_loss, no_params, num_epochs, runtime, tr_losses, _ = sp.train(ds=train_choices, \n",
    "                                                                            num_items=len(train_alt_codex), \n",
    "                                                                            alternative_codex=train_alt_codex,\n",
    "                                                                            epochs=2000, \n",
    "                                                                            lr=1e-3, \n",
    "                                                                            wd=1e-5, \n",
    "                                                                            verbose=True, \n",
    "                                                                            Model=sp.JointModel if 'augmented' not in model_name else sp.ENDModel,\n",
    "                                                                            **kwargs)\n",
    "    tr_losses = np.array(tr_losses)\n",
    "    task_loss = tr_loss - tr_losses[-1, -1]\n",
    "    result.append([i, dataset_name, model_name, 'train', 'overall', num_agents, num_alternatives, num_observations, float(task_loss), num_epochs, runtime, no_params])\n",
    "    result.append([i, dataset_name, model_name, 'train + reg', 'overall', num_agents, num_alternatives, num_observations, float(tr_loss), num_epochs, runtime, no_params])\n",
    "\n",
    "    ytest_hat = model.forward(xtest, xltest, poisson_covariates=poisson_covariates_test, mnl_covariates=mnl_covariates_test) if model_name == 'conditionally independent' else model.forward(xtest, xltest, mnl_covariates=mnl_covariates_test)\n",
    "    test_loss, test_loss_terms = model.loss_func(ytest_hat, ytest, xtest, xltest, mnl_covariates=mnl_covariates_test, poisson_covariates=poisson_covariates_test, train=False) if model_name == 'conditionally independent' else model.loss_func(ytest_hat, ytest, xtest, xltest, mnl_covariates=mnl_covariates_test, train=False)\n",
    "    result.append([i, dataset_name, model_name, 'test', 'overall', num_agents, num_alternatives, num_observations, float(test_loss), num_epochs, runtime, no_params])\n",
    "    for i, loss_type in enumerate(['choice', 'length', 'reg']):\n",
    "        result.append([i, dataset_name, model_name, 'train', num_agents, num_alternatives, num_observations, loss_type, float(tr_losses[-1, i]), num_epochs, runtime, no_params])\n",
    "        result.append([i, dataset_name, model_name, 'test', num_agents, num_alternatives, num_observations, loss_type, float(test_loss_terms[i]), num_epochs, runtime, no_params])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f356d86a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def full_train(model_name, length_k, length_reg, mnl_k, rank_reg, dataset_name, dataset, mnl_covariates=None, length_covariates=None, num_ranks=0):\n",
    "    if (model_name == 'conditionally independent') & ((mnl_covariates == None) | (length_covariates == None)):\n",
    "        return\n",
    "    \n",
    "    shuffled = dataset.sample(frac=1,random_state=0).reset_index(drop=True)\n",
    "    train = shuffled\n",
    "\n",
    "    train_choices, train_agent_codex, train_alt_codex, train_ballot = dp.prep_dataset(train)\n",
    "    num_observations = train_choices[0].shape[0]\n",
    "    num_agents = len(train_agent_codex)\n",
    "    num_alternatives = len(train_alt_codex)\n",
    "    max_length = train_ballot.length.max()\n",
    "    print(\"Dataset: {}\\tn: {}\\tm: {}\\tN: {}\\tAvg. len: {}\\tMax len: {}\".format(dataset_name, num_agents, num_alternatives, num_observations, num_observations/float(num_agents), max_length))\n",
    "\n",
    "    if mnl_covariates:\n",
    "        '''\n",
    "        RCV data has no covariates, so this condition is a placeholder. \n",
    "        If your dataset includes agent/alternative + agent covariates, \n",
    "           pass those along as mnl_covariates + length_covariates pandas dataframes.\n",
    "        '''\n",
    "        mnl_covariates_train = mnl_covariates.loc[train_agent_codex, train_alt_codex]\n",
    "        poisson_covariates_train = length_covariates.loc[train_agent_codex].values.astype(np.float32)\n",
    "        mnl_covariates_test = mnl_covariates.loc[test_agent_codex, train_alt_codex]\n",
    "        poisson_covariates_test = length_covariates.loc[test_agent_codex].values.astype(np.float32)\n",
    "    else: \n",
    "        mnl_covariates_train, poisson_covariates_train = None, None\n",
    "    \n",
    "    kwargs={'mnl_fixed_effects': True,\n",
    "            'mnl_covariates': mnl_covariates_train,\n",
    "            'max_length': max_length\n",
    "           }\n",
    "    if model_name == 'length dependent':\n",
    "        kwargs['categorical'] = True\n",
    "        kwargs['dependent'] = True\n",
    "        kwargs['length_k'] = length_k\n",
    "        kwargs['length_reg'] = length_reg\n",
    "    elif model_name == 'fully independent':\n",
    "        kwargs['categorical'] = True\n",
    "        kwargs['dependent'] = False\n",
    "    elif model_name == 'conditionally independent':\n",
    "        kwargs['dependent'] = False\n",
    "        kwargs['poisson_covariates'] = poisson_covariates_train\n",
    "    elif model_name == 'augmented':\n",
    "        kwargs['position_dependent_end'] = False\n",
    "    elif model_name == 'stratified augmented':\n",
    "        kwargs['mnl_k'] = mnl_k\n",
    "        kwargs['rank_reg'] = rank_reg\n",
    "    else:\n",
    "        pass\n",
    "    model, tr_loss, no_params, num_epochs, runtime, tr_losses, _ = sp.train(ds=train_choices, \n",
    "                                                                            num_items=len(train_alt_codex),\n",
    "                                                                            alternative_codex=train_alt_codex,\n",
    "                                                                            epochs=2000, \n",
    "                                                                            lr=1e-3, \n",
    "                                                                            wd=1e-5, \n",
    "                                                                            verbose=True, \n",
    "                                                                            Model=sp.JointModel if 'augmented' not in model_name else sp.ENDModel,\n",
    "                                                                            **kwargs)\n",
    "    return (dataset_name, model_name, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "39da52f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = []\n",
    "datasets = []\n",
    "for year, dictionary in rcv_datasets.items():\n",
    "    for race, dataset in dictionary.items():\n",
    "        dataset_names.append('{} {}'.format(year, race))\n",
    "        datasets.append(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d6ddb2d3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. params:  6\n",
      "Epoch: 25, Training Loss: 1.0880882740020752\n",
      "Epoch: 50, Training Loss: 1.0396840572357178\n",
      "Runtime: 130.548424243927\n",
      "Loss: 1.0370935201644897\n",
      "No. params:  32\n",
      "Runtime: 1083.7257833480835\n",
      "Loss: 1.7649872303009033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ameloa/.local/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. params:  8\n",
      "Epoch: 25, Training Loss: 1.4801052808761597\n",
      "Runtime: 57.9708137512207\n",
      "Loss: 1.4775547981262207\n",
      "No. params:  20\n",
      "Epoch: 25, Training Loss: 1.4704163074493408\n",
      "Epoch: 50, Training Loss: 1.4103748798370361\n",
      "Runtime: 220.40343761444092\n",
      "Loss: 1.402119517326355\n",
      "No. params:  9\n",
      "Epoch: 25, Training Loss: 2.051460027694702\n",
      "Runtime: 1580.8113481998444\n",
      "Loss: 2.0460429191589355\n",
      "No. params:  32\n",
      "Epoch: 25, Training Loss: 1.8148621320724487\n",
      "Runtime: 1057.536144733429\n",
      "Loss: 1.8148621320724487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. params:  4\n",
      "Epoch: 25, Training Loss: 1.278597354888916\n",
      "Epoch: 50, Training Loss: 1.1779919862747192\n",
      "Epoch: 75, Training Loss: 1.130394458770752\n",
      "Epoch: 100, Training Loss: 1.1072520017623901\n",
      "Epoch: 125, Training Loss: 1.0955541133880615\n",
      "Epoch: 150, Training Loss: 1.0892794132232666\n",
      "Epoch: 175, Training Loss: 1.0856399536132812\n",
      "Runtime: 410.5330810546875\n",
      "Loss: 1.084797978401184\n",
      "No. params:  16\n",
      "Epoch: 25, Training Loss: 1.8307139873504639\n",
      "Runtime: 487.6011760234833\n",
      "Loss: 1.8307139873504639\n",
      "No. params:  11\n",
      "Epoch: 25, Training Loss: 1.8469250202178955\n",
      "Epoch: 50, Training Loss: 1.8372153043746948\n",
      "Runtime: 1240.445945262909\n",
      "Loss: 1.8365472555160522\n",
      "No. params:  20\n",
      "Epoch: 25, Training Loss: 1.0983995199203491\n",
      "Epoch: 50, Training Loss: 1.0207717418670654\n",
      "Epoch: 75, Training Loss: 0.9966899752616882\n",
      "Epoch: 100, Training Loss: 0.9884338974952698\n",
      "Epoch: 125, Training Loss: 0.9844461679458618\n",
      "Runtime: 3858.272723674774\n",
      "Loss: 0.9835864901542664\n",
      "No. params:  32\n",
      "Runtime: 1110.367553472519\n",
      "Loss: 1.8011326789855957\n",
      "No. params:  12\n",
      "Epoch: 25, Training Loss: 1.053289771080017\n",
      "Epoch: 50, Training Loss: 1.0255032777786255\n",
      "Epoch: 75, Training Loss: 1.0209386348724365\n",
      "Runtime: 272.86399030685425\n",
      "Loss: 1.0208393335342407\n",
      "No. params:  11\n",
      "Epoch: 25, Training Loss: 1.8464463949203491\n",
      "Epoch: 50, Training Loss: 1.8368585109710693\n",
      "Runtime: 1708.3294496536255\n",
      "Loss: 1.8362014293670654\n",
      "No. params:  8\n",
      "Epoch: 25, Training Loss: 1.6554011106491089\n",
      "Epoch: 50, Training Loss: 1.5820828676223755\n",
      "Epoch: 75, Training Loss: 1.5475221872329712\n",
      "Epoch: 100, Training Loss: 1.5204966068267822\n",
      "Epoch: 125, Training Loss: 1.500046730041504\n",
      "Epoch: 150, Training Loss: 1.4855602979660034\n",
      "Epoch: 175, Training Loss: 1.4756382703781128\n",
      "Epoch: 200, Training Loss: 1.4688514471054077\n",
      "Epoch: 225, Training Loss: 1.4641172885894775\n",
      "Epoch: 250, Training Loss: 1.4607189893722534\n",
      "Runtime: 546.0132787227631\n",
      "Loss: 1.4592235088348389\n",
      "No. params:  13\n",
      "Epoch: 25, Training Loss: 1.634358525276184\n",
      "Epoch: 50, Training Loss: 1.6230823993682861\n",
      "Runtime: 1440.8867423534393\n",
      "Loss: 1.621597409248352\n",
      "No. params:  8\n",
      "Epoch: 25, Training Loss: 1.5181537866592407\n",
      "Epoch: 50, Training Loss: 1.509661078453064\n",
      "Runtime: 1161.6908094882965\n",
      "Loss: 1.5088924169540405\n",
      "No. params:  14\n",
      "Epoch: 25, Training Loss: 1.6963143348693848\n",
      "Runtime: 623.8963050842285\n",
      "Loss: 1.6939417123794556\n",
      "No. params:  6\n",
      "Epoch: 25, Training Loss: 1.3419901132583618\n",
      "Epoch: 50, Training Loss: 1.224360466003418\n",
      "Epoch: 75, Training Loss: 1.16615629196167\n",
      "Epoch: 100, Training Loss: 1.136641025543213\n",
      "Epoch: 125, Training Loss: 1.1209449768066406\n",
      "Epoch: 150, Training Loss: 1.1121468544006348\n",
      "Epoch: 175, Training Loss: 1.1069247722625732\n",
      "Epoch: 200, Training Loss: 1.1036427021026611\n",
      "Runtime: 530.9248213768005\n",
      "Loss: 1.103235125541687\n",
      "No. params:  14\n",
      "Epoch: 25, Training Loss: 1.6339671611785889\n",
      "Runtime: 746.7250235080719\n",
      "Loss: 1.6316030025482178\n",
      "No. params:  12\n",
      "Epoch: 25, Training Loss: 1.137559175491333\n",
      "Epoch: 50, Training Loss: 0.8920997381210327\n",
      "Epoch: 75, Training Loss: 0.7593609094619751\n",
      "Epoch: 100, Training Loss: 0.6830984950065613\n",
      "Epoch: 125, Training Loss: 0.6354801058769226\n",
      "Epoch: 150, Training Loss: 0.6032299995422363\n",
      "Epoch: 175, Training Loss: 0.5800390839576721\n",
      "Epoch: 200, Training Loss: 0.562809407711029\n",
      "Epoch: 225, Training Loss: 0.5498066544532776\n",
      "Epoch: 250, Training Loss: 0.5399183034896851\n",
      "Epoch: 275, Training Loss: 0.532374918460846\n",
      "Epoch: 300, Training Loss: 0.5266159176826477\n",
      "Epoch: 325, Training Loss: 0.5222232341766357\n",
      "Epoch: 350, Training Loss: 0.5188781023025513\n",
      "Runtime: 1383.7548828125\n",
      "Loss: 0.5172702670097351\n",
      "No. params:  5\n",
      "Epoch: 25, Training Loss: 1.759596347808838\n",
      "Epoch: 50, Training Loss: 1.6934047937393188\n",
      "Epoch: 75, Training Loss: 1.654828429222107\n",
      "Epoch: 100, Training Loss: 1.624382495880127\n",
      "Epoch: 125, Training Loss: 1.6029653549194336\n",
      "Epoch: 150, Training Loss: 1.5888895988464355\n",
      "Epoch: 175, Training Loss: 1.5798323154449463\n",
      "Epoch: 200, Training Loss: 1.5739328861236572\n",
      "Epoch: 225, Training Loss: 1.5699639320373535\n",
      "Runtime: 540.09645652771\n",
      "Loss: 1.5675697326660156\n",
      "No. params:  12\n",
      "Epoch: 25, Training Loss: 1.1438199281692505\n",
      "Epoch: 50, Training Loss: 0.8996378183364868\n",
      "Epoch: 75, Training Loss: 0.7674180865287781\n",
      "Epoch: 100, Training Loss: 0.6912581920623779\n",
      "Epoch: 125, Training Loss: 0.6434956192970276\n",
      "Epoch: 150, Training Loss: 0.6109686493873596\n",
      "Epoch: 175, Training Loss: 0.5874600410461426\n",
      "Epoch: 200, Training Loss: 0.5699424743652344\n",
      "Epoch: 225, Training Loss: 0.5567096471786499\n",
      "Epoch: 250, Training Loss: 0.546647310256958\n",
      "Epoch: 275, Training Loss: 0.5389752388000488\n",
      "Epoch: 300, Training Loss: 0.5331234931945801\n",
      "Epoch: 325, Training Loss: 0.5286644697189331\n",
      "Epoch: 350, Training Loss: 0.525273859500885\n",
      "Runtime: 1329.9665360450745\n",
      "Loss: 0.523547351360321\n",
      "No. params:  8\n",
      "Epoch: 25, Training Loss: 1.6846950054168701\n",
      "Epoch: 50, Training Loss: 1.6080100536346436\n",
      "Epoch: 75, Training Loss: 1.5742186307907104\n",
      "Epoch: 100, Training Loss: 1.5482773780822754\n",
      "Epoch: 125, Training Loss: 1.5288102626800537\n",
      "Epoch: 150, Training Loss: 1.5151704549789429\n",
      "Epoch: 175, Training Loss: 1.505995750427246\n",
      "Epoch: 200, Training Loss: 1.4998724460601807\n",
      "Epoch: 225, Training Loss: 1.4957162141799927\n",
      "Runtime: 332.8182964324951\n",
      "Loss: 1.4929091930389404\n",
      "No. params:  13\n",
      "Epoch: 25, Training Loss: 1.6394364833831787\n",
      "Epoch: 50, Training Loss: 1.6291999816894531\n",
      "Runtime: 822.5217955112457\n",
      "Loss: 1.6282753944396973\n",
      "No. params:  32\n",
      "Epoch: 25, Training Loss: 1.8094353675842285\n",
      "Runtime: 818.6472873687744\n",
      "Loss: 1.8094353675842285\n",
      "No. params:  5\n",
      "Epoch: 25, Training Loss: 1.6303398609161377\n",
      "Epoch: 50, Training Loss: 1.6224327087402344\n",
      "Runtime: 755.8674955368042\n",
      "Loss: 1.621898889541626\n",
      "No. params:  32\n",
      "Epoch: 25, Training Loss: 1.867619514465332\n",
      "Runtime: 832.4013545513153\n",
      "Loss: 1.867619514465332\n",
      "No. params:  12\n",
      "Epoch: 25, Training Loss: 1.1375524997711182\n",
      "Epoch: 50, Training Loss: 0.8917132616043091\n",
      "Epoch: 75, Training Loss: 0.7582718729972839\n",
      "Epoch: 100, Training Loss: 0.6812291741371155\n",
      "Epoch: 125, Training Loss: 0.6329384446144104\n",
      "Epoch: 150, Training Loss: 0.6002092957496643\n",
      "Epoch: 175, Training Loss: 0.5767130255699158\n",
      "Epoch: 200, Training Loss: 0.559282124042511\n",
      "Epoch: 225, Training Loss: 0.5461364984512329\n",
      "Epoch: 250, Training Loss: 0.5361430048942566\n",
      "Epoch: 275, Training Loss: 0.5285211801528931\n",
      "Epoch: 300, Training Loss: 0.5227038860321045\n",
      "Epoch: 325, Training Loss: 0.5182672142982483\n",
      "Epoch: 350, Training Loss: 0.5148893594741821\n",
      "Runtime: 1303.1424472332\n",
      "Loss: 0.5132660865783691\n",
      "No. params:  5\n",
      "Epoch: 25, Training Loss: 1.7551603317260742\n",
      "Epoch: 50, Training Loss: 1.6888666152954102\n",
      "Epoch: 75, Training Loss: 1.6497364044189453\n",
      "Epoch: 100, Training Loss: 1.618863582611084\n",
      "Epoch: 125, Training Loss: 1.5971249341964722\n",
      "Epoch: 150, Training Loss: 1.582810878753662\n",
      "Epoch: 175, Training Loss: 1.5735862255096436\n",
      "Epoch: 200, Training Loss: 1.5675736665725708\n",
      "Epoch: 225, Training Loss: 1.56352961063385\n",
      "Runtime: 370.732706785202\n",
      "Loss: 1.5608923435211182\n",
      "No. params:  12\n",
      "Epoch: 25, Training Loss: 1.1240302324295044\n",
      "Epoch: 50, Training Loss: 0.8759940266609192\n",
      "Epoch: 75, Training Loss: 0.7413814663887024\n",
      "Epoch: 100, Training Loss: 0.6638793349266052\n",
      "Epoch: 125, Training Loss: 0.6156311631202698\n",
      "Epoch: 150, Training Loss: 0.5832188129425049\n",
      "Epoch: 175, Training Loss: 0.5601246356964111\n",
      "Epoch: 200, Training Loss: 0.5430695414543152\n",
      "Epoch: 225, Training Loss: 0.530232846736908\n",
      "Epoch: 250, Training Loss: 0.5204808115959167\n",
      "Epoch: 275, Training Loss: 0.5130442380905151\n",
      "Epoch: 300, Training Loss: 0.5073680877685547\n",
      "Epoch: 325, Training Loss: 0.503038227558136\n",
      "Epoch: 350, Training Loss: 0.49974164366722107\n",
      "Runtime: 1204.5574712753296\n",
      "Loss: 0.4983537793159485\n",
      "No. params:  8\n",
      "Runtime: 60.68942618370056\n",
      "Loss: 1.539310336112976\n",
      "No. params:  20\n",
      "Epoch: 25, Training Loss: 1.4466313123703003\n",
      "Epoch: 50, Training Loss: 1.397119164466858\n",
      "Epoch: 75, Training Loss: 1.3880904912948608\n",
      "Runtime: 229.9281668663025\n",
      "Loss: 1.38740873336792\n",
      "No. params:  5\n",
      "Epoch: 25, Training Loss: 1.6055845022201538\n",
      "Epoch: 50, Training Loss: 1.597214698791504\n",
      "Runtime: 778.5808846950531\n",
      "Loss: 1.5965509414672852\n",
      "No. params:  4\n",
      "Epoch: 25, Training Loss: 1.2869592905044556\n",
      "Epoch: 50, Training Loss: 1.1874080896377563\n",
      "Epoch: 75, Training Loss: 1.1403834819793701\n",
      "Epoch: 100, Training Loss: 1.1175240278244019\n",
      "Epoch: 125, Training Loss: 1.1059314012527466\n",
      "Epoch: 150, Training Loss: 1.0996674299240112\n",
      "Epoch: 175, Training Loss: 1.0960010290145874\n",
      "Runtime: 418.8842921257019\n",
      "Loss: 1.0950490236282349\n",
      "No. params:  8\n",
      "Epoch: 25, Training Loss: 1.6829168796539307\n",
      "Epoch: 50, Training Loss: 1.6073819398880005\n",
      "Epoch: 75, Training Loss: 1.573864221572876\n",
      "Epoch: 100, Training Loss: 1.5481536388397217\n",
      "Epoch: 125, Training Loss: 1.528926968574524\n",
      "Epoch: 150, Training Loss: 1.5154931545257568\n",
      "Epoch: 175, Training Loss: 1.5064647197723389\n",
      "Epoch: 200, Training Loss: 1.5004295110702515\n",
      "Epoch: 225, Training Loss: 1.4963184595108032\n",
      "Runtime: 393.86126255989075\n",
      "Loss: 1.4935309886932373\n",
      "No. params:  20\n",
      "Epoch: 25, Training Loss: 1.0625178813934326\n",
      "Epoch: 50, Training Loss: 0.9868683815002441\n",
      "Epoch: 75, Training Loss: 0.9641907215118408\n",
      "Epoch: 100, Training Loss: 0.9566426277160645\n",
      "Epoch: 125, Training Loss: 0.9529868960380554\n",
      "Runtime: 3348.4325244426727\n",
      "Loss: 0.95257568359375\n",
      "No. params:  5\n",
      "Epoch: 25, Training Loss: 1.617212176322937\n",
      "Epoch: 50, Training Loss: 1.6090352535247803\n",
      "Runtime: 1200.481784582138\n",
      "Loss: 1.6084853410720825\n",
      "No. params:  5\n",
      "Epoch: 25, Training Loss: 1.558125376701355\n",
      "Epoch: 50, Training Loss: 1.5491199493408203\n",
      "Runtime: 1155.778712272644\n",
      "Loss: 1.5482016801834106\n",
      "No. params:  20\n",
      "Epoch: 25, Training Loss: 1.5774545669555664\n",
      "Epoch: 50, Training Loss: 1.3466987609863281\n",
      "Epoch: 75, Training Loss: 1.2085518836975098\n",
      "Epoch: 100, Training Loss: 1.1156796216964722\n",
      "Epoch: 125, Training Loss: 1.0510191917419434\n",
      "Epoch: 150, Training Loss: 1.004226565361023\n",
      "Epoch: 175, Training Loss: 0.9690989255905151\n",
      "Epoch: 200, Training Loss: 0.9420349597930908\n",
      "Epoch: 225, Training Loss: 0.920788049697876\n",
      "Epoch: 250, Training Loss: 0.9037889838218689\n",
      "Epoch: 275, Training Loss: 0.8898990750312805\n",
      "Epoch: 300, Training Loss: 0.878323495388031\n",
      "Epoch: 325, Training Loss: 0.8685290217399597\n",
      "Epoch: 350, Training Loss: 0.8601459264755249\n",
      "Epoch: 375, Training Loss: 0.8529074192047119\n",
      "Epoch: 400, Training Loss: 0.8466171622276306\n",
      "Epoch: 425, Training Loss: 0.841126561164856\n",
      "Epoch: 450, Training Loss: 0.8363207578659058\n",
      "Epoch: 475, Training Loss: 0.8321055769920349\n",
      "Epoch: 500, Training Loss: 0.8284034729003906\n",
      "Epoch: 525, Training Loss: 0.8251495957374573\n",
      "Epoch: 550, Training Loss: 0.8222899436950684\n",
      "Runtime: 1696.7880749702454\n",
      "Loss: 0.8208431005477905\n",
      "No. params:  5\n",
      "Epoch: 25, Training Loss: 1.7612160444259644\n",
      "Epoch: 50, Training Loss: 1.6939061880111694\n",
      "Epoch: 75, Training Loss: 1.654740571975708\n",
      "Epoch: 100, Training Loss: 1.623894453048706\n",
      "Epoch: 125, Training Loss: 1.6021462678909302\n",
      "Epoch: 150, Training Loss: 1.5878660678863525\n",
      "Epoch: 175, Training Loss: 1.5787657499313354\n",
      "Epoch: 200, Training Loss: 1.57295560836792\n",
      "Epoch: 225, Training Loss: 1.5691494941711426\n",
      "Runtime: 533.1208965778351\n",
      "Loss: 1.5673844814300537\n",
      "No. params:  6\n",
      "Epoch: 25, Training Loss: 1.3018889427185059\n",
      "Epoch: 50, Training Loss: 1.1782963275909424\n",
      "Epoch: 75, Training Loss: 1.119493007659912\n",
      "Epoch: 100, Training Loss: 1.0907361507415771\n",
      "Epoch: 125, Training Loss: 1.075911283493042\n",
      "Epoch: 150, Training Loss: 1.067805290222168\n",
      "Epoch: 175, Training Loss: 1.0630993843078613\n",
      "Runtime: 589.8121867179871\n",
      "Loss: 1.0605881214141846\n",
      "No. params:  6\n",
      "Epoch: 25, Training Loss: 1.0822501182556152\n",
      "Epoch: 50, Training Loss: 1.027109980583191\n",
      "Runtime: 164.1131660938263\n",
      "Loss: 1.0223886966705322\n",
      "No. params:  9\n",
      "Epoch: 25, Training Loss: 2.0935370922088623\n",
      "Runtime: 1492.5499868392944\n",
      "Loss: 2.088216781616211\n",
      "No. params:  49\n",
      "Epoch: 25, Training Loss: 1.6149004697799683\n",
      "Runtime: 1190.181211233139\n",
      "Loss: 1.6134624481201172\n",
      "No. params:  8\n",
      "Epoch: 25, Training Loss: 1.4803521633148193\n",
      "Runtime: 43.224435806274414\n",
      "Loss: 1.4777312278747559\n",
      "No. params:  49\n",
      "Epoch: 25, Training Loss: 1.536990761756897\n",
      "Runtime: 1081.482215642929\n",
      "Loss: 1.5356199741363525\n",
      "No. params:  20\n",
      "Epoch: 25, Training Loss: 1.4591740369796753\n",
      "Epoch: 50, Training Loss: 1.3968110084533691\n",
      "Epoch: 75, Training Loss: 1.3873668909072876\n",
      "Runtime: 199.75830006599426\n",
      "Loss: 1.3872758150100708\n",
      "No. params:  13\n",
      "Epoch: 25, Training Loss: 1.7009350061416626\n",
      "Epoch: 50, Training Loss: 1.6900622844696045\n",
      "Runtime: 896.8523671627045\n",
      "Loss: 1.6886054277420044\n",
      "No. params:  8\n",
      "Epoch: 25, Training Loss: 1.5799285173416138\n",
      "Epoch: 50, Training Loss: 1.5721131563186646\n",
      "Runtime: 970.3341708183289\n",
      "Loss: 1.5716928243637085\n",
      "No. params:  8\n",
      "Epoch: 25, Training Loss: 1.5499321222305298\n",
      "Epoch: 50, Training Loss: 1.5418875217437744\n",
      "Runtime: 781.2549896240234\n",
      "Loss: 1.5413559675216675\n",
      "No. params:  9\n",
      "Epoch: 25, Training Loss: 2.0924367904663086\n",
      "Runtime: 1616.6346235275269\n",
      "Loss: 2.0870468616485596\n",
      "No. params:  14\n",
      "Epoch: 25, Training Loss: 1.6283838748931885\n",
      "Runtime: 685.6323947906494\n",
      "Loss: 1.6258821487426758\n",
      "No. params:  6\n",
      "Epoch: 25, Training Loss: 1.3053961992263794\n",
      "Epoch: 50, Training Loss: 1.1823769807815552\n",
      "Epoch: 75, Training Loss: 1.124131202697754\n",
      "Epoch: 100, Training Loss: 1.0958259105682373\n",
      "Epoch: 125, Training Loss: 1.081329345703125\n",
      "Epoch: 150, Training Loss: 1.0734553337097168\n",
      "Epoch: 175, Training Loss: 1.0689148902893066\n",
      "Runtime: 512.6751110553741\n",
      "Loss: 1.0667972564697266\n",
      "No. params:  20\n",
      "Runtime: 170.20249819755554\n",
      "Loss: 1.5001939535140991\n",
      "No. params:  13\n",
      "Epoch: 25, Training Loss: 1.7084639072418213\n",
      "Epoch: 50, Training Loss: 1.6985126733779907\n",
      "Runtime: 889.7757260799408\n",
      "Loss: 1.6977165937423706\n",
      "No. params:  8\n",
      "Epoch: 25, Training Loss: 1.827361822128296\n",
      "Epoch: 50, Training Loss: 1.816082239151001\n",
      "Runtime: 1012.5049915313721\n",
      "Loss: 1.8142690658569336\n",
      "No. params:  11\n",
      "Epoch: 25, Training Loss: 1.8317711353302002\n",
      "Epoch: 50, Training Loss: 1.822480320930481\n",
      "Runtime: 1792.9331579208374\n",
      "Loss: 1.821948528289795\n",
      "No. params:  49\n",
      "Epoch: 25, Training Loss: 1.5473805665969849\n",
      "Runtime: 1285.5271289348602\n",
      "Loss: 1.5459167957305908\n",
      "No. params:  9\n",
      "Epoch: 25, Training Loss: 2.148094892501831\n",
      "Runtime: 1002.0729959011078\n",
      "Loss: 2.142788887023926\n",
      "No. params:  12\n",
      "Epoch: 25, Training Loss: 1.0624884366989136\n",
      "Epoch: 50, Training Loss: 1.0381022691726685\n",
      "Runtime: 214.46118831634521\n",
      "Loss: 1.0347726345062256\n",
      "No. params:  8\n",
      "Epoch: 25, Training Loss: 1.8015601634979248\n",
      "Epoch: 50, Training Loss: 1.7908581495285034\n",
      "Runtime: 1431.4392049312592\n",
      "Loss: 1.7893562316894531\n",
      "No. params:  8\n",
      "Epoch: 25, Training Loss: 1.4880179166793823\n",
      "Runtime: 56.508567810058594\n",
      "Loss: 1.4867899417877197\n",
      "No. params:  8\n",
      "Runtime: 124.0062849521637\n",
      "Loss: 1.570427656173706\n",
      "No. params:  8\n",
      "Epoch: 25, Training Loss: 1.8025728464126587\n",
      "Epoch: 50, Training Loss: 1.7920860052108765\n",
      "Runtime: 1293.7247440814972\n",
      "Loss: 1.7906099557876587\n",
      "No. params:  11\n",
      "Epoch: 25, Training Loss: 1.9050328731536865\n",
      "Epoch: 50, Training Loss: 1.8948955535888672\n",
      "Runtime: 983.5033583641052\n",
      "Loss: 1.8940919637680054\n",
      "No. params:  20\n",
      "Epoch: 25, Training Loss: 1.4699323177337646\n",
      "Epoch: 50, Training Loss: 1.4064791202545166\n",
      "Epoch: 75, Training Loss: 1.3960152864456177\n",
      "Runtime: 197.72161078453064\n",
      "Loss: 1.3955841064453125\n",
      "No. params:  12\n",
      "Epoch: 25, Training Loss: 1.0633217096328735\n",
      "Epoch: 50, Training Loss: 1.0386860370635986\n",
      "Runtime: 215.8804852962494\n",
      "Loss: 1.0351258516311646\n",
      "No. params:  8\n",
      "Epoch: 25, Training Loss: 1.5010933876037598\n",
      "Epoch: 50, Training Loss: 1.4938503503799438\n",
      "Runtime: 712.6445291042328\n",
      "Loss: 1.493653655052185\n",
      "No. params:  20\n",
      "Runtime: 180.74097418785095\n",
      "Loss: 1.4083285331726074\n",
      "No. params:  6\n",
      "Epoch: 25, Training Loss: 1.2931102514266968\n",
      "Epoch: 50, Training Loss: 1.1679530143737793\n",
      "Epoch: 75, Training Loss: 1.1078978776931763\n",
      "Epoch: 100, Training Loss: 1.0783286094665527\n",
      "Epoch: 125, Training Loss: 1.0630486011505127\n",
      "Epoch: 150, Training Loss: 1.0546972751617432\n",
      "Epoch: 175, Training Loss: 1.0498497486114502\n",
      "Runtime: 414.95280027389526\n",
      "Loss: 1.0470614433288574\n",
      "No. params:  20\n",
      "Runtime: 197.47693347930908\n",
      "Loss: 1.517867088317871\n",
      "No. params:  4\n",
      "Epoch: 25, Training Loss: 1.2888596057891846\n",
      "Epoch: 50, Training Loss: 1.1893830299377441\n",
      "Epoch: 75, Training Loss: 1.142520785331726\n",
      "Epoch: 100, Training Loss: 1.119821548461914\n",
      "Epoch: 125, Training Loss: 1.1083742380142212\n",
      "Epoch: 150, Training Loss: 1.1022340059280396\n",
      "Epoch: 175, Training Loss: 1.0986682176589966\n",
      "Runtime: 506.17946553230286\n",
      "Loss: 1.097939372062683\n",
      "No. params:  8\n",
      "Epoch: 25, Training Loss: 1.4421099424362183\n",
      "Runtime: 55.509047508239746\n",
      "Loss: 1.4412966966629028\n",
      "No. params:  6\n",
      "Epoch: 25, Training Loss: 1.1507554054260254\n",
      "Epoch: 50, Training Loss: 1.0894441604614258\n",
      "Runtime: 165.44562578201294\n",
      "Loss: 1.0831371545791626\n",
      "No. params:  12\n",
      "Epoch: 25, Training Loss: 1.115882396697998\n",
      "Epoch: 50, Training Loss: 1.0816915035247803\n",
      "Runtime: 250.2563076019287\n",
      "Loss: 1.0775671005249023\n",
      "No. params:  4\n",
      "Epoch: 25, Training Loss: 1.3087615966796875\n",
      "Epoch: 50, Training Loss: 1.2122036218643188\n",
      "Epoch: 75, Training Loss: 1.1683573722839355\n",
      "Epoch: 100, Training Loss: 1.1478631496429443\n",
      "Epoch: 125, Training Loss: 1.137870192527771\n",
      "Epoch: 150, Training Loss: 1.1326439380645752\n",
      "Runtime: 458.9548387527466\n",
      "Loss: 1.129936695098877\n",
      "No. params:  12\n",
      "Epoch: 25, Training Loss: 1.1616716384887695\n",
      "Epoch: 50, Training Loss: 0.9084841012954712\n",
      "Epoch: 75, Training Loss: 0.7706342935562134\n",
      "Epoch: 100, Training Loss: 0.6909787058830261\n",
      "Epoch: 125, Training Loss: 0.6411793231964111\n",
      "Epoch: 150, Training Loss: 0.6076594591140747\n",
      "Epoch: 175, Training Loss: 0.5838140249252319\n",
      "Epoch: 200, Training Loss: 0.5662334561347961\n",
      "Epoch: 225, Training Loss: 0.553000807762146\n",
      "Epoch: 250, Training Loss: 0.5429367423057556\n",
      "Epoch: 275, Training Loss: 0.5352494716644287\n",
      "Epoch: 300, Training Loss: 0.5293696522712708\n",
      "Epoch: 325, Training Loss: 0.5248731374740601\n",
      "Epoch: 350, Training Loss: 0.5214384198188782\n",
      "Runtime: 929.4269704818726\n",
      "Loss: 0.5195812582969666\n",
      "No. params:  16\n",
      "Runtime: 768.1471083164215\n",
      "Loss: 1.8157141208648682\n",
      "No. params:  8\n",
      "Epoch: 25, Training Loss: 1.4628825187683105\n",
      "Runtime: 79.02033042907715\n",
      "Loss: 1.4587533473968506\n",
      "No. params:  16\n",
      "Epoch: 25, Training Loss: 1.8303438425064087\n",
      "Runtime: 699.2335228919983\n",
      "Loss: 1.8303438425064087\n",
      "No. params:  6\n",
      "Epoch: 25, Training Loss: 1.0897083282470703\n",
      "Epoch: 50, Training Loss: 1.0448216199874878\n",
      "Runtime: 162.58247709274292\n",
      "Loss: 1.0431866645812988\n",
      "No. params:  12\n",
      "Epoch: 25, Training Loss: 1.0673524141311646\n",
      "Epoch: 50, Training Loss: 1.0438824892044067\n",
      "Runtime: 242.64739894866943\n",
      "Loss: 1.040974497795105\n",
      "No. params:  13\n",
      "Epoch: 25, Training Loss: 1.640082597732544\n",
      "Epoch: 50, Training Loss: 1.6286735534667969\n",
      "Runtime: 1267.370481967926\n",
      "Loss: 1.6270649433135986\n",
      "No. params:  20\n",
      "Epoch: 25, Training Loss: 1.5215706825256348\n",
      "Epoch: 50, Training Loss: 1.3046929836273193\n",
      "Epoch: 75, Training Loss: 1.1723427772521973\n",
      "Epoch: 100, Training Loss: 1.0832515954971313\n",
      "Epoch: 125, Training Loss: 1.0209938287734985\n",
      "Epoch: 150, Training Loss: 0.975510835647583\n",
      "Epoch: 175, Training Loss: 0.9409527778625488\n",
      "Epoch: 200, Training Loss: 0.9139888882637024\n",
      "Epoch: 225, Training Loss: 0.8925440907478333\n",
      "Epoch: 250, Training Loss: 0.8751875162124634\n",
      "Epoch: 275, Training Loss: 0.860893726348877\n",
      "Epoch: 300, Training Loss: 0.8489266633987427\n",
      "Epoch: 325, Training Loss: 0.8387670516967773\n",
      "Epoch: 350, Training Loss: 0.830053985118866\n",
      "Epoch: 375, Training Loss: 0.8225336074829102\n",
      "Epoch: 400, Training Loss: 0.816017746925354\n",
      "Epoch: 425, Training Loss: 0.8103593587875366\n",
      "Epoch: 450, Training Loss: 0.8054388761520386\n",
      "Epoch: 475, Training Loss: 0.8011561632156372\n",
      "Epoch: 500, Training Loss: 0.7974257469177246\n",
      "Epoch: 525, Training Loss: 0.7941757440567017\n",
      "Epoch: 550, Training Loss: 0.7913460731506348\n",
      "Runtime: 1265.195491552353\n",
      "Loss: 0.7902204990386963\n",
      "No. params:  8\n",
      "Runtime: 109.38760805130005\n",
      "Loss: 1.492926001548767\n",
      "No. params:  5\n",
      "Epoch: 25, Training Loss: 1.550972819328308\n",
      "Epoch: 50, Training Loss: 1.5412484407424927\n",
      "Runtime: 1268.9481225013733\n",
      "Loss: 1.5400596857070923\n",
      "No. params:  20\n",
      "Epoch: 25, Training Loss: 1.0558513402938843\n",
      "Epoch: 50, Training Loss: 0.9726978540420532\n",
      "Epoch: 75, Training Loss: 0.9483000040054321\n",
      "Epoch: 100, Training Loss: 0.9401806592941284\n",
      "Epoch: 125, Training Loss: 0.9362218976020813\n",
      "Runtime: 3352.582254886627\n",
      "Loss: 0.9353647232055664\n",
      "No. params:  27\n",
      "Epoch: 25, Training Loss: 1.527194857597351\n",
      "Epoch: 50, Training Loss: 1.468083381652832\n",
      "Epoch: 75, Training Loss: 1.4524192810058594\n",
      "Epoch: 100, Training Loss: 1.4454667568206787\n",
      "Epoch: 125, Training Loss: 1.4416145086288452\n",
      "Runtime: 5189.253684282303\n",
      "Loss: 1.4404268264770508\n",
      "No. params:  14\n",
      "Epoch: 25, Training Loss: 1.624219298362732\n",
      "Runtime: 732.6158287525177\n",
      "Loss: 1.6217442750930786\n",
      "No. params:  27\n",
      "Epoch: 25, Training Loss: 1.4791719913482666\n",
      "Epoch: 50, Training Loss: 1.4209295511245728\n",
      "Epoch: 75, Training Loss: 1.4057279825210571\n",
      "Epoch: 100, Training Loss: 1.3990002870559692\n",
      "Epoch: 125, Training Loss: 1.3952761888504028\n",
      "Runtime: 4613.878212690353\n",
      "Loss: 1.3943212032318115\n",
      "No. params:  16\n",
      "Runtime: 769.0259034633636\n",
      "Loss: 1.7745212316513062\n",
      "No. params:  8\n",
      "Runtime: 112.77961301803589\n",
      "Loss: 1.5134445428848267\n",
      "No. params:  49\n",
      "Epoch: 25, Training Loss: 1.5844725370407104\n",
      "Runtime: 1320.8608877658844\n",
      "Loss: 1.5831594467163086\n",
      "No. params:  20\n",
      "Epoch: 25, Training Loss: 1.1015596389770508\n",
      "Epoch: 50, Training Loss: 1.0232913494110107\n",
      "Epoch: 75, Training Loss: 0.9987943172454834\n",
      "Epoch: 100, Training Loss: 0.9903344511985779\n",
      "Epoch: 125, Training Loss: 0.9862510561943054\n",
      "Runtime: 2956.717445373535\n",
      "Loss: 0.9851729869842529\n",
      "No. params:  20\n",
      "Runtime: 176.7910315990448\n",
      "Loss: 1.5148966312408447\n",
      "No. params:  4\n",
      "Epoch: 25, Training Loss: 1.2887507677078247\n",
      "Epoch: 50, Training Loss: 1.1889879703521729\n",
      "Epoch: 75, Training Loss: 1.141859531402588\n",
      "Epoch: 100, Training Loss: 1.118963599205017\n",
      "Epoch: 125, Training Loss: 1.1073760986328125\n",
      "Epoch: 150, Training Loss: 1.10113525390625\n",
      "Epoch: 175, Training Loss: 1.0974953174591064\n",
      "Runtime: 558.5145635604858\n",
      "Loss: 1.0966498851776123\n",
      "No. params:  14\n",
      "Epoch: 25, Training Loss: 1.6984906196594238\n",
      "Runtime: 650.8542408943176\n",
      "Loss: 1.6965059041976929\n",
      "No. params:  27\n",
      "Epoch: 25, Training Loss: 1.5405523777008057\n",
      "Epoch: 50, Training Loss: 1.4790278673171997\n",
      "Epoch: 75, Training Loss: 1.4625071287155151\n",
      "Epoch: 100, Training Loss: 1.4551738500595093\n",
      "Epoch: 125, Training Loss: 1.4511144161224365\n",
      "Runtime: 4200.3976628780365\n",
      "Loss: 1.4495619535446167\n",
      "No. params:  6\n",
      "Epoch: 25, Training Loss: 1.0870649814605713\n",
      "Epoch: 50, Training Loss: 1.0388190746307373\n",
      "Runtime: 128.0789511203766\n",
      "Loss: 1.0362647771835327\n",
      "No. params:  20\n",
      "Runtime: 176.73248934745789\n",
      "Loss: 1.4661365747451782\n",
      "No. params:  11\n",
      "Epoch: 25, Training Loss: 1.7901421785354614\n",
      "Epoch: 50, Training Loss: 1.7810554504394531\n",
      "Runtime: 1728.4564595222473\n",
      "Loss: 1.7806304693222046\n",
      "No. params:  8\n",
      "Epoch: 25, Training Loss: 1.6894274950027466\n",
      "Epoch: 50, Training Loss: 1.6155624389648438\n",
      "Epoch: 75, Training Loss: 1.5829718112945557\n",
      "Epoch: 100, Training Loss: 1.5574281215667725\n",
      "Epoch: 125, Training Loss: 1.538163661956787\n",
      "Epoch: 150, Training Loss: 1.5246222019195557\n",
      "Epoch: 175, Training Loss: 1.5154354572296143\n",
      "Epoch: 200, Training Loss: 1.5092158317565918\n",
      "Epoch: 225, Training Loss: 1.5049200057983398\n",
      "Epoch: 250, Training Loss: 1.5018643140792847\n",
      "Runtime: 549.381840467453\n",
      "Loss: 1.5014594793319702\n",
      "No. params:  16\n",
      "Epoch: 25, Training Loss: 1.889647126197815\n",
      "Runtime: 676.3915846347809\n",
      "Loss: 1.889647126197815\n",
      "No. params:  20\n",
      "Epoch: 25, Training Loss: 1.0881896018981934\n",
      "Epoch: 50, Training Loss: 1.0101187229156494\n",
      "Epoch: 75, Training Loss: 0.9866871237754822\n",
      "Epoch: 100, Training Loss: 0.9788380265235901\n",
      "Epoch: 125, Training Loss: 0.9750496745109558\n",
      "Runtime: 2391.9052772521973\n",
      "Loss: 0.9744249582290649\n",
      "No. params:  8\n",
      "Epoch: 25, Training Loss: 1.5602837800979614\n",
      "Epoch: 50, Training Loss: 1.5526202917099\n",
      "Runtime: 1167.3024098873138\n",
      "Loss: 1.5523078441619873\n",
      "No. params:  8\n",
      "Epoch: 25, Training Loss: 1.8510535955429077\n",
      "Epoch: 50, Training Loss: 1.8418734073638916\n",
      "Runtime: 1294.02286195755\n",
      "Loss: 1.840948462486267\n",
      "No. params:  27\n",
      "Epoch: 25, Training Loss: 1.5379751920700073\n",
      "Epoch: 50, Training Loss: 1.476552128791809\n",
      "Epoch: 75, Training Loss: 1.460160493850708\n",
      "Epoch: 100, Training Loss: 1.4528926610946655\n",
      "Epoch: 125, Training Loss: 1.4488694667816162\n",
      "Runtime: 3514.1091198921204\n",
      "Loss: 1.4474289417266846\n",
      "No. params:  48\n",
      "Epoch: 25, Training Loss: 1.1739468574523926\n",
      "Epoch: 50, Training Loss: 1.1066596508026123\n",
      "Epoch: 75, Training Loss: 1.084232211112976\n",
      "Epoch: 100, Training Loss: 1.0721986293792725\n",
      "Epoch: 125, Training Loss: 1.0644842386245728\n",
      "Epoch: 150, Training Loss: 1.0591118335723877\n",
      "Epoch: 175, Training Loss: 1.0551835298538208\n",
      "Epoch: 200, Training Loss: 1.0522191524505615\n",
      "Runtime: 6345.871757030487\n",
      "Loss: 1.0518133640289307\n",
      "No. params:  6\n",
      "Epoch: 25, Training Loss: 1.3013547658920288\n",
      "Epoch: 50, Training Loss: 1.1781446933746338\n",
      "Epoch: 75, Training Loss: 1.1195266246795654\n",
      "Epoch: 100, Training Loss: 1.0908446311950684\n",
      "Epoch: 125, Training Loss: 1.0760409832000732\n",
      "Epoch: 150, Training Loss: 1.0679340362548828\n",
      "Epoch: 175, Training Loss: 1.0632193088531494\n",
      "Runtime: 553.6477084159851\n",
      "Loss: 1.0606995820999146\n",
      "No. params:  48\n",
      "Epoch: 25, Training Loss: 1.1923631429672241\n",
      "Epoch: 50, Training Loss: 1.126413106918335\n",
      "Epoch: 75, Training Loss: 1.104203462600708\n",
      "Epoch: 100, Training Loss: 1.0922762155532837\n",
      "Epoch: 125, Training Loss: 1.0846308469772339\n",
      "Epoch: 150, Training Loss: 1.0793007612228394\n",
      "Epoch: 175, Training Loss: 1.0753953456878662\n",
      "Epoch: 200, Training Loss: 1.072442889213562\n",
      "Runtime: 6175.445001125336\n",
      "Loss: 1.0720380544662476\n",
      "No. params:  49\n",
      "Epoch: 25, Training Loss: 1.5342713594436646\n",
      "Runtime: 1354.5423874855042\n",
      "Loss: 1.5328457355499268\n",
      "No. params:  8\n",
      "Epoch: 25, Training Loss: 1.6693559885025024\n",
      "Epoch: 50, Training Loss: 1.5904406309127808\n",
      "Epoch: 75, Training Loss: 1.5562362670898438\n",
      "Epoch: 100, Training Loss: 1.5306541919708252\n",
      "Epoch: 125, Training Loss: 1.511696696281433\n",
      "Epoch: 150, Training Loss: 1.4984843730926514\n",
      "Epoch: 175, Training Loss: 1.489574670791626\n",
      "Epoch: 200, Training Loss: 1.4835666418075562\n",
      "Epoch: 225, Training Loss: 1.4794256687164307\n",
      "Epoch: 250, Training Loss: 1.4764832258224487\n",
      "Runtime: 528.9050109386444\n",
      "Loss: 1.4763840436935425\n",
      "No. params:  20\n",
      "Epoch: 25, Training Loss: 1.478220820426941\n",
      "Epoch: 50, Training Loss: 1.413262963294983\n",
      "Epoch: 75, Training Loss: 1.4021443128585815\n",
      "Runtime: 254.50337553024292\n",
      "Loss: 1.401579737663269\n",
      "No. params:  9\n",
      "Epoch: 25, Training Loss: 2.094012975692749\n",
      "Runtime: 1436.1330988407135\n",
      "Loss: 2.0886309146881104\n",
      "No. params:  27\n",
      "Epoch: 25, Training Loss: 1.5945895910263062\n",
      "Epoch: 50, Training Loss: 1.5316418409347534\n",
      "Epoch: 75, Training Loss: 1.514770269393921\n",
      "Epoch: 100, Training Loss: 1.5072709321975708\n",
      "Epoch: 125, Training Loss: 1.503116250038147\n",
      "Runtime: 2841.4341654777527\n",
      "Loss: 1.501427412033081\n",
      "No. params:  8\n",
      "Epoch: 25, Training Loss: 1.7986648082733154\n",
      "Epoch: 50, Training Loss: 1.7880715131759644\n",
      "Runtime: 1477.6657750606537\n",
      "Loss: 1.7865824699401855\n",
      "No. params:  48\n",
      "Epoch: 25, Training Loss: 1.222508430480957\n",
      "Epoch: 50, Training Loss: 1.1530340909957886\n",
      "Epoch: 75, Training Loss: 1.1309088468551636\n",
      "Epoch: 100, Training Loss: 1.1193959712982178\n",
      "Epoch: 125, Training Loss: 1.112153172492981\n",
      "Epoch: 150, Training Loss: 1.1071373224258423\n",
      "Epoch: 175, Training Loss: 1.1034529209136963\n",
      "Epoch: 200, Training Loss: 1.1006470918655396\n",
      "Runtime: 5573.212182998657\n",
      "Loss: 1.1006470918655396\n",
      "No. params:  8\n",
      "Runtime: 103.00909209251404\n",
      "Loss: 1.5509434938430786\n",
      "No. params:  5\n",
      "Epoch: 25, Training Loss: 1.7632826566696167\n",
      "Epoch: 50, Training Loss: 1.6979727745056152\n",
      "Epoch: 75, Training Loss: 1.6592028141021729\n",
      "Epoch: 100, Training Loss: 1.6284639835357666\n",
      "Epoch: 125, Training Loss: 1.606814980506897\n",
      "Epoch: 150, Training Loss: 1.5926052331924438\n",
      "Epoch: 175, Training Loss: 1.5835248231887817\n",
      "Epoch: 200, Training Loss: 1.5776875019073486\n",
      "Epoch: 225, Training Loss: 1.5738253593444824\n",
      "Runtime: 582.4690728187561\n",
      "Loss: 1.571918249130249\n",
      "No. params:  20\n",
      "Epoch: 25, Training Loss: 1.5700414180755615\n",
      "Epoch: 50, Training Loss: 1.3417973518371582\n",
      "Epoch: 75, Training Loss: 1.2046260833740234\n",
      "Epoch: 100, Training Loss: 1.1127864122390747\n",
      "Epoch: 125, Training Loss: 1.0491347312927246\n",
      "Epoch: 150, Training Loss: 1.0032213926315308\n",
      "Epoch: 175, Training Loss: 0.9688414335250854\n",
      "Epoch: 200, Training Loss: 0.9424057006835938\n",
      "Epoch: 225, Training Loss: 0.9216815233230591\n",
      "Epoch: 250, Training Loss: 0.9051203727722168\n",
      "Epoch: 275, Training Loss: 0.8916027545928955\n",
      "Epoch: 300, Training Loss: 0.8803461194038391\n",
      "Epoch: 325, Training Loss: 0.8708224296569824\n",
      "Epoch: 350, Training Loss: 0.8626648783683777\n",
      "Epoch: 375, Training Loss: 0.8556122779846191\n",
      "Epoch: 400, Training Loss: 0.8494730591773987\n",
      "Epoch: 425, Training Loss: 0.8441044688224792\n",
      "Epoch: 450, Training Loss: 0.8393961787223816\n",
      "Epoch: 475, Training Loss: 0.8352584838867188\n",
      "Epoch: 500, Training Loss: 0.8316175937652588\n",
      "Epoch: 525, Training Loss: 0.8284114003181458\n",
      "Epoch: 550, Training Loss: 0.8255885243415833\n",
      "Runtime: 1784.675091266632\n",
      "Loss: 0.8243566751480103\n",
      "No. params:  48\n",
      "Epoch: 25, Training Loss: 1.1825162172317505\n",
      "Epoch: 50, Training Loss: 1.1143981218338013\n",
      "Epoch: 75, Training Loss: 1.0918768644332886\n",
      "Epoch: 100, Training Loss: 1.0798274278640747\n",
      "Epoch: 125, Training Loss: 1.0721049308776855\n",
      "Epoch: 150, Training Loss: 1.0667225122451782\n",
      "Epoch: 175, Training Loss: 1.062780737876892\n",
      "Epoch: 200, Training Loss: 1.0598002672195435\n",
      "Runtime: 5186.15246629715\n",
      "Loss: 1.059291958808899\n"
     ]
    }
   ],
   "source": [
    "model_names=['fully independent', 'conditionally independent', 'length dependent', 'augmented', 'position-dependent augmented', 'stratified augmented']\n",
    "kfolds=5\n",
    "kfold_results = Parallel(n_jobs=30)(delayed(kfold_train_test)(i, model_name, 10, 0.0, 10, 0.0, dataset_name, dataset) \n",
    "                                      for i in range(kfolds)\n",
    "                                      for model_name in model_names\n",
    "                                      for dataset_name, dataset in zip(dataset_names, datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ed676a3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3698322/373112899.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  overall_results['dataset label'] = overall_results['dataset'].map({'2018 BOS': 'RCV1',\n",
      "/tmp/ipykernel_3698322/373112899.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  overall_results['Model'] = overall_results['model name'].map({'fully independent': 'C-I',\n",
      "/tmp/ipykernel_3698322/373112899.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  overall_results['model category'] = overall_results['model name'].map({'fully independent': 'composite',\n"
     ]
    }
   ],
   "source": [
    "kfold_train_df = pd.DataFrame([subitem for result in kfold_results if result is not None for subitem in result],\n",
    "                             columns=['i', 'dataset', 'model name', 'loss type', 'term', 'n', 'm', 'num_obs', 'loss', 'num epochs', 'runtime', 'no params'])\n",
    "full_results = kfold_train_df[(kfold_train_df['loss type']!='train + reg')&(kfold_train_df['term']!='reg')]\n",
    "overall_results = kfold_train_df[(kfold_train_df['term']=='overall') & (kfold_train_df['loss type']!='train + reg')]\n",
    "overall_results['dataset label'] = overall_results['dataset'].map({'2018 BOS': 'RCV1',\n",
    "                                                                   '2019 DA': 'RCV2',\n",
    "                                                                   '2019 BOS': 'RCV3',\n",
    "                                                                   '2019 M': 'RCV4',\n",
    "                                                                   '2018 M': 'RCV5',\n",
    "                                                                   '1819 SFUSD': 'SC1',\n",
    "                                                                   '1718 SFUSD': 'SC2'})\n",
    "overall_results['Model'] = overall_results['model name'].map({'fully independent': 'C-I',\n",
    "                                                              'conditionally independent': 'C-CI',\n",
    "                                                              'length dependent': 'C-LD',\n",
    "                                                              'augmented': 'A',\n",
    "                                                              'position-dependent augmented': 'A-PD',\n",
    "                                                              'stratified augmented': 'A-S'})\n",
    "overall_results['model category'] = overall_results['model name'].map({'fully independent': 'composite',\n",
    "                                                                       'conditionally independent': 'composite',\n",
    "                                                                       'length dependent': 'composite',\n",
    "                                                                       'augmented': 'augmented',\n",
    "                                                                       'position-dependent augmented': 'augmented',\n",
    "                                                                       'stratified augmented': 'augmented'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ed803e12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/seaborn/categorical.py:1781: UserWarning: You passed a edgecolor/edgecolors ((0.996078431372549, 0.8892425990003844, 0.5665974625144176)) for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(x, y, label=hue_level,\n",
      "/usr/local/lib/python3.10/dist-packages/seaborn/categorical.py:1781: UserWarning: You passed a edgecolor/edgecolors ((0.9949711649365629, 0.5974778931180315, 0.15949250288350636)) for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(x, y, label=hue_level,\n",
      "/usr/local/lib/python3.10/dist-packages/seaborn/categorical.py:1781: UserWarning: You passed a edgecolor/edgecolors ((0.7952941176470588, 0.2958246828143022, 0.008027681660899655)) for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(x, y, label=hue_level,\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_names = ['fully independent', 'conditionally independent', 'length dependent', 'augmented', 'position-dependent augmented', 'stratified augmented']\n",
    "hue_order = ['C-I', 'C-CI', 'C-LD', 'A', 'A-PD', 'A-S']\n",
    "palette = sns.color_palette(\"Blues\", n_colors=3)+sns.color_palette(\"YlOrBr\", n_colors=3)\n",
    "fig, ax = plt.subplots(1,1,figsize=(6,4))\n",
    "\n",
    "data = overall_results[overall_results['loss type']=='test']\n",
    "data = data.assign(num_alternatives=data['dataset'].map({'2018 BOS': 3, \n",
    "                                                         '2018 M': 8, \n",
    "                                                         '2019 DA': 4, \n",
    "                                                         '2019 M': 7, \n",
    "                                                         '2019 BOS': 4})).sort_values(by='num_alternatives')\n",
    "\n",
    "# data = data[data.Model=='A']\n",
    "sns.pointplot(data=data, x='dataset label', y='loss', hue='Model', markers=['o','o','o','x','x', 'x'],\n",
    "              hue_order=hue_order, palette=palette, dodge=True, join=False, alpha=0.5, ax=ax).set(xlabel='Dataset',\n",
    "                                                                                                     ylabel='NLL')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5d34607c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "/home/ameloa/partial-orders/src/stratified_pytorch.py:549: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_likelihoods = F.log_softmax(self.length_logits.weight.flatten())[x_extra[:,4]-1]\n",
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 2019 BOS\tn: 23698\tm: 4\tN: 48434\tAvg. len: 2.043801164655245\tMax len: 4\n",
      "No. params:  8\n",
      "Epoch: 25, Training Loss: 1.4777312278747559\n",
      "Runtime: 55.344786643981934\n",
      "Loss: 1.4776451587677002\n",
      "Dataset: 2018 BOS\tn: 33394\tm: 3\tN: 68148\tAvg. len: 2.0407258789004015\tMax len: 3\n",
      "No. params:  6\n",
      "Epoch: 25, Training Loss: 1.0382486581802368\n",
      "Epoch: 50, Training Loss: 1.0006600618362427\n",
      "Runtime: 158.52763676643372\n",
      "Loss: 0.9989178776741028\n",
      "Dataset: 2019 BOS\tn: 23698\tm: 4\tN: 48434\tAvg. len: 2.043801164655245\tMax len: 4\n",
      "No. params:  20\n",
      "Epoch: 25, Training Loss: 1.44297194480896\n",
      "Epoch: 50, Training Loss: 1.4033596515655518\n",
      "Runtime: 216.01244497299194\n",
      "Loss: 1.4013351202011108\n",
      "Dataset: 2019 DA\tn: 193492\tm: 4\tN: 448815\tAvg. len: 2.3195532631840075\tMax len: 4\n",
      "No. params:  8\n",
      "Runtime: 98.96809124946594\n",
      "Loss: 1.5541460514068604\n",
      "Dataset: 2018 BOS\tn: 33394\tm: 3\tN: 68148\tAvg. len: 2.0407258789004015\tMax len: 3\n",
      "No. params:  12\n",
      "Epoch: 25, Training Loss: 1.0251072645187378\n",
      "Epoch: 50, Training Loss: 1.0102695226669312\n",
      "Runtime: 261.5652356147766\n",
      "Loss: 1.0085591077804565\n",
      "Dataset: 2019 DA\tn: 193492\tm: 4\tN: 448815\tAvg. len: 2.3195532631840075\tMax len: 4\n",
      "No. params:  20\n",
      "Runtime: 170.34251713752747\n",
      "Loss: 1.5189459323883057\n",
      "Dataset: 2018 BOS\tn: 33394\tm: 3\tN: 68148\tAvg. len: 2.0407258789004015\tMax len: 3\n",
      "No. params:  4\n",
      "Epoch: 25, Training Loss: 1.2619116306304932\n",
      "Epoch: 50, Training Loss: 1.165297508239746\n",
      "Epoch: 75, Training Loss: 1.1267025470733643\n",
      "Epoch: 100, Training Loss: 1.110558032989502\n",
      "Epoch: 125, Training Loss: 1.1032156944274902\n",
      "Epoch: 150, Training Loss: 1.0994294881820679\n",
      "Runtime: 336.52122807502747\n",
      "Loss: 1.098697304725647\n",
      "Dataset: 2019 BOS\tn: 23698\tm: 4\tN: 48434\tAvg. len: 2.043801164655245\tMax len: 4\n",
      "No. params:  5\n",
      "Epoch: 25, Training Loss: 1.7383482456207275\n",
      "Epoch: 50, Training Loss: 1.6779125928878784\n",
      "Epoch: 75, Training Loss: 1.6357989311218262\n",
      "Epoch: 100, Training Loss: 1.6077512502670288\n",
      "Epoch: 125, Training Loss: 1.5911824703216553\n",
      "Epoch: 150, Training Loss: 1.5816433429718018\n",
      "Epoch: 175, Training Loss: 1.5759609937667847\n",
      "Epoch: 200, Training Loss: 1.5723624229431152\n",
      "Runtime: 395.57851696014404\n",
      "Loss: 1.5711848735809326\n",
      "Dataset: 2019 BOS\tn: 23698\tm: 4\tN: 48434\tAvg. len: 2.043801164655245\tMax len: 4\n",
      "No. params:  8\n",
      "Epoch: 25, Training Loss: 1.6585700511932373\n",
      "Epoch: 50, Training Loss: 1.5931308269500732\n",
      "Epoch: 75, Training Loss: 1.5572247505187988\n",
      "Epoch: 100, Training Loss: 1.5318703651428223\n",
      "Epoch: 125, Training Loss: 1.5156174898147583\n",
      "Epoch: 150, Training Loss: 1.5056763887405396\n",
      "Epoch: 175, Training Loss: 1.4995110034942627\n",
      "Epoch: 200, Training Loss: 1.4955151081085205\n",
      "Runtime: 399.47071385383606\n",
      "Loss: 1.4933621883392334\n",
      "Dataset: 2018 BOS\tn: 33394\tm: 3\tN: 68148\tAvg. len: 2.0407258789004015\tMax len: 3\n",
      "No. params:  6\n",
      "Epoch: 25, Training Loss: 1.2481828927993774\n",
      "Epoch: 50, Training Loss: 1.1274986267089844\n",
      "Epoch: 75, Training Loss: 1.0789717435836792\n",
      "Epoch: 100, Training Loss: 1.0580235719680786\n",
      "Epoch: 125, Training Loss: 1.048182487487793\n",
      "Epoch: 150, Training Loss: 1.0431214570999146\n",
      "Runtime: 423.53360199928284\n",
      "Loss: 1.0408354997634888\n",
      "Dataset: 2019 M\tn: 178924\tm: 7\tN: 461186\tAvg. len: 2.5775524803827325\tMax len: 6\n",
      "No. params:  14\n",
      "Epoch: 25, Training Loss: 1.6643249988555908\n",
      "Runtime: 390.1669533252716\n",
      "Loss: 1.6636836528778076\n",
      "Dataset: 2018 M\tn: 253866\tm: 8\tN: 639747\tAvg. len: 2.5200184349223607\tMax len: 3\n",
      "No. params:  16\n",
      "Runtime: 374.05918884277344\n",
      "Loss: 1.8163450956344604\n",
      "Dataset: 2019 DA\tn: 193492\tm: 4\tN: 448815\tAvg. len: 2.3195532631840075\tMax len: 4\n",
      "No. params:  8\n",
      "Epoch: 25, Training Loss: 1.560065746307373\n",
      "Runtime: 591.5274906158447\n",
      "Loss: 1.5551211833953857\n",
      "Dataset: 2019 DA\tn: 193492\tm: 4\tN: 448815\tAvg. len: 2.3195532631840075\tMax len: 4\n",
      "No. params:  5\n",
      "Epoch: 25, Training Loss: 1.6179070472717285\n",
      "Runtime: 602.2774546146393\n",
      "Loss: 1.6124740839004517\n",
      "Dataset: 2019 M\tn: 178924\tm: 7\tN: 461186\tAvg. len: 2.5775524803827325\tMax len: 6\n",
      "No. params:  8\n",
      "Epoch: 25, Training Loss: 1.8181785345077515\n",
      "Epoch: 50, Training Loss: 1.8116945028305054\n",
      "Runtime: 667.621235370636\n",
      "Loss: 1.811493992805481\n",
      "Dataset: 2018 M\tn: 253866\tm: 8\tN: 639747\tAvg. len: 2.5200184349223607\tMax len: 3\n",
      "No. params:  32\n",
      "Runtime: 623.8650183677673\n",
      "Loss: 1.798281192779541\n",
      "Dataset: 2019 M\tn: 178924\tm: 7\tN: 461186\tAvg. len: 2.5775524803827325\tMax len: 6\n",
      "No. params:  13\n",
      "Epoch: 25, Training Loss: 1.67462158203125\n",
      "Epoch: 50, Training Loss: 1.666991114616394\n",
      "Runtime: 696.3264760971069\n",
      "Loss: 1.666222095489502\n",
      "Dataset: 2018 M\tn: 253866\tm: 8\tN: 639747\tAvg. len: 2.5200184349223607\tMax len: 3\n",
      "No. params:  9\n",
      "Epoch: 25, Training Loss: 2.086709499359131\n",
      "Runtime: 699.4546897411346\n",
      "Loss: 2.0833146572113037\n",
      "Dataset: 2018 M\tn: 253866\tm: 8\tN: 639747\tAvg. len: 2.5200184349223607\tMax len: 3\n",
      "No. params:  11\n",
      "Epoch: 25, Training Loss: 1.8279725313186646\n",
      "Runtime: 770.0591404438019\n",
      "Loss: 1.8222683668136597\n",
      "Dataset: 2019 M\tn: 178924\tm: 7\tN: 461186\tAvg. len: 2.5775524803827325\tMax len: 6\n",
      "No. params:  49\n",
      "Epoch: 25, Training Loss: 1.548970341682434\n",
      "Runtime: 836.1330142021179\n",
      "Loss: 1.548757553100586\n",
      "Dataset: 2018 BOS\tn: 33394\tm: 3\tN: 68148\tAvg. len: 2.0407258789004015\tMax len: 3\n",
      "No. params:  33\n",
      "Epoch: 25, Training Loss: 1.032726526260376\n",
      "Epoch: 50, Training Loss: 0.7818450927734375\n",
      "Epoch: 75, Training Loss: 0.6630920767784119\n",
      "Epoch: 100, Training Loss: 0.5997660160064697\n",
      "Epoch: 125, Training Loss: 0.5615473985671997\n",
      "Epoch: 150, Training Loss: 0.5363627672195435\n",
      "Epoch: 175, Training Loss: 0.5189223885536194\n",
      "Epoch: 200, Training Loss: 0.5065687894821167\n",
      "Epoch: 225, Training Loss: 0.4977506399154663\n",
      "Epoch: 250, Training Loss: 0.4914478659629822\n",
      "Epoch: 275, Training Loss: 0.48694831132888794\n",
      "Epoch: 300, Training Loss: 0.4837440252304077\n",
      "Runtime: 1795.3440551757812\n",
      "Loss: 0.48312437534332275\n",
      "Dataset: 2019 BOS\tn: 23698\tm: 4\tN: 48434\tAvg. len: 2.043801164655245\tMax len: 4\n",
      "No. params:  44\n",
      "Epoch: 25, Training Loss: 1.4913133382797241\n",
      "Epoch: 50, Training Loss: 1.253584623336792\n",
      "Epoch: 75, Training Loss: 1.1186007261276245\n",
      "Epoch: 100, Training Loss: 1.034601092338562\n",
      "Epoch: 125, Training Loss: 0.9788439273834229\n",
      "Epoch: 150, Training Loss: 0.9396593570709229\n",
      "Epoch: 175, Training Loss: 0.9111040830612183\n",
      "Epoch: 200, Training Loss: 0.889694094657898\n",
      "Epoch: 225, Training Loss: 0.8731289505958557\n",
      "Epoch: 250, Training Loss: 0.8599148392677307\n",
      "Epoch: 275, Training Loss: 0.8491181135177612\n",
      "Epoch: 300, Training Loss: 0.8401446342468262\n",
      "Epoch: 325, Training Loss: 0.8326027989387512\n",
      "Epoch: 350, Training Loss: 0.8262233734130859\n",
      "Epoch: 375, Training Loss: 0.8208078145980835\n",
      "Epoch: 400, Training Loss: 0.8161998987197876\n",
      "Epoch: 425, Training Loss: 0.8122763633728027\n",
      "Epoch: 450, Training Loss: 0.808937668800354\n",
      "Epoch: 475, Training Loss: 0.8061001896858215\n",
      "Runtime: 2068.8869466781616\n",
      "Loss: 0.8052860498428345\n",
      "Dataset: 2019 DA\tn: 193492\tm: 4\tN: 448815\tAvg. len: 2.3195532631840075\tMax len: 4\n",
      "No. params:  44\n",
      "Epoch: 25, Training Loss: 1.0716774463653564\n",
      "Epoch: 50, Training Loss: 1.0077083110809326\n",
      "Epoch: 75, Training Loss: 0.9924112558364868\n",
      "Epoch: 100, Training Loss: 0.9869620203971863\n",
      "Runtime: 4293.445891618729\n",
      "Loss: 0.9850556254386902\n"
     ]
    }
   ],
   "source": [
    "model_names=['fully independent', 'conditionally independent', 'length dependent', 'augmented', 'position-dependent augmented', 'stratified augmented']\n",
    "full_train_results = Parallel(n_jobs=30)(delayed(full_train)(model_name, length_k, length_reg, mnl_k, rank_reg, dataset_name, dataset) \n",
    "                                         for model_name in model_names\n",
    "                                         for dataset_name, dataset, length_k, length_reg, mnl_k, rank_reg in zip(dataset_names, \n",
    "                                                                                                                 datasets, \n",
    "                                                                                                                 length_ks, \n",
    "                                                                                                                 length_regs, \n",
    "                                                                                                                 mnl_ks, \n",
    "                                                                                                                 rank_regs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "97502c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = collections.defaultdict(dict)\n",
    "for model_tuple in full_train_results:\n",
    "    if model_tuple:\n",
    "        model_dict[model_tuple[0]][model_tuple[1]] = model_tuple[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8199c50e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc47d034",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Generate preferences / modal lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1720c9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_datasets(i, dataset, dataset_name, model_name, model):\n",
    "    random.seed(model_name+str(i))\n",
    "    length_results = []\n",
    "    length_summary = []\n",
    "    demand_results=[]\n",
    "    true_lengths = dataset.num_ranked.values\n",
    "    num_agents = true_lengths.size\n",
    "    if (model_name == 'conditionally independent') and model.school_choice:\n",
    "        sampled_lengths, sampled_prefs = model.sample_preferences()\n",
    "    else:\n",
    "        num_agents = num_agents if model.mnl_covariates is None else model.mnl_covariates.shape[0]\n",
    "        sampled_lengths, sampled_prefs = model.sample_preferences(num_samples=num_agents)\n",
    "    length_summary.append([i, dataset_name, model_name, num_agents, model.num_items, model.numel(), 'length', 'mean', sampled_lengths.mean()])\n",
    "    length_summary.append([i, dataset_name, model_name, num_agents, model.num_items, model.numel(), 'length', 'median', np.median(sampled_lengths)])\n",
    "    length_summary.append([i, dataset_name, model_name, num_agents, model.num_items, model.numel(), 'length', 'mode', scipy.stats.mode(sampled_lengths).mode[0]])\n",
    "    length_summary.append([i, dataset_name, model_name, num_agents, model.num_items, model.numel(), 'length', 'std', sampled_lengths.std()])\n",
    "\n",
    "    length_results.extend([[i, dataset_name, model_name, length] for length in sampled_lengths])\n",
    "\n",
    "    sampled_candidates = np.array(model.alternative_codex)[sampled_prefs[sampled_prefs<(model.num_items+1)]]\n",
    "    candidates, counts = np.unique(sampled_candidates, return_counts=True)\n",
    "    for candidate, proportion in zip(candidates, counts/counts.sum()):\n",
    "        demand_results.append([i, dataset_name, model_name, num_agents, model.num_items, model.numel(), 'overall candidate', candidate, proportion])\n",
    "    sampled_candidates = np.array(model.alternative_codex)[sampled_prefs[:,0]]\n",
    "    candidates, counts = np.unique(sampled_candidates, return_counts=True)\n",
    "    for candidate, proportion in zip(candidates, counts/counts.sum()):\n",
    "        demand_results.append([i, dataset_name, model_name, num_agents, model.num_items, model.numel(), 'top-1 candidate', candidate, proportion])\n",
    "    return length_results, length_summary+demand_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f7b5dd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019 M\n",
      "2019 BOS\n",
      "2019 DA\n",
      "2018 M\n",
      "2018 BOS\n"
     ]
    }
   ],
   "source": [
    "true_demand_results = []\n",
    "true_length_results = []\n",
    "for dataset_name, dataset in zip(dataset_names, datasets):\n",
    "    print(dataset_name)\n",
    "    model = model_dict[dataset_name]['fully independent']\n",
    "    true_lengths = dataset.num_ranked.values\n",
    "    num_agents = true_lengths.size\n",
    "    true_demand_results.extend([[0, dataset_name, 'true', num_agents, model.num_items, 0, 'length', 'mean', true_lengths.mean()], \n",
    "                                [0, dataset_name, 'true', num_agents, model.num_items, 0, 'length', 'median', np.median(true_lengths)], \n",
    "                                [0, dataset_name, 'true', num_agents, model.num_items, 0, 'length', 'mode', scipy.stats.mode(true_lengths).mode[0]], \n",
    "                                [0, dataset_name, 'true', num_agents, model.num_items, 0, 'length', 'std', true_lengths.std()]])\n",
    "    \n",
    "    true_length_results.extend([[0, dataset_name, 'true', length] for length in true_lengths])\n",
    "\n",
    "    candidates, counts = np.unique(dataset.alternatives.explode().values, return_counts=True)\n",
    "    for candidate, proportion in zip(candidates, counts/counts.sum()):\n",
    "        true_demand_results.append([0, dataset_name, 'true', num_agents, model.num_items, 0, 'overall candidate', candidate, proportion])\n",
    "    top1_candidates = [candidate_list[0] for candidate_list in dataset.alternatives]\n",
    "    candidates_top1, counts = np.unique(top1_candidates, return_counts=True)\n",
    "    for candidate, proportion in zip(candidates_top1, counts/counts.sum()):\n",
    "        true_demand_results.append([0, dataset_name, 'true', num_agents, model.num_items, 0, 'top-1 candidate', candidate, proportion])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "22b0bf30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ameloa/.local/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sampling_results = Parallel(n_jobs=30)(delayed(sample_datasets)(i, \n",
    "                                                                rcv_datasets[dataset_name.split()[0]][dataset_name.split()[1]], \n",
    "                                                                dataset_name, \n",
    "                                                                model_name, \n",
    "                                                                model) \n",
    "                                       for i in range(100)\n",
    "                                       for dataset_name, dictionary in model_dict.items()\n",
    "                                       for model_name, model in dictionary.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a23a33ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = true_demand_results + [subitem for _, item in sampling_results for subitem in item]\n",
    "sampling_df = pd.DataFrame(results, columns=['i', 'dataset', 'model name', 'n', 'm', 'no_params', 'metric_type', 'metric', 'value'])\n",
    "sampling_df['model category'] = sampling_df['model name'].map({'fully independent': 'composite',\n",
    "                                                               'conditionally independent': 'composite',\n",
    "                                                               'length dependent': 'composite',\n",
    "                                                               'augmented': 'augmented',\n",
    "                                                               'position-dependent augmented': 'augmented',\n",
    "                                                               'stratified augmented': 'augmented'})\n",
    "sampling_df['dataset label'] = sampling_df['dataset'].map({'2018 BOS': 'RCV1',\n",
    "                                                           '2019 DA': 'RCV2',\n",
    "                                                           '2019 BOS': 'RCV3',\n",
    "                                                           '2019 M': 'RCV4',\n",
    "                                                           '2018 M': 'RCV5'})\n",
    "sampling_df['name label'] = sampling_df['model name'].map({'true': 'true', \n",
    "                                                           'fully independent': 'C-I',\n",
    "                                                           'conditionally independent': 'C-CI',\n",
    "                                                           'length dependent': 'C-LD',\n",
    "                                                           'augmented': 'A',\n",
    "                                                           'position-dependent augmented': 'A-PD',\n",
    "                                                           'stratified augmented': 'A-S'})\n",
    "sampling_df['display name'] = sampling_df['metric'].apply(lambda x: x.replace(' ', '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f107aa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "length_results = true_length_results.copy()\n",
    "[length_results.extend(item) for item, _ in sampling_results]\n",
    "length_df = pd.DataFrame(length_results, columns=['i', 'dataset', 'model_name', 'Length'])\n",
    "length_df['Model'] = length_df['model_name'].map({'true': 'true', \n",
    "                                                  'fully independent': 'C-I',\n",
    "                                                  'conditionally independent': 'C-CI',\n",
    "                                                  'length dependent': 'C-LD',\n",
    "                                                  'augmented': 'A',\n",
    "                                                  'position-dependent augmented': 'A-PD',\n",
    "                                                  'stratified augmented': 'A-S'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5151b115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = '2018 M'\n",
    "name = '2018 Mayor'\n",
    "hue_order = ['true', 'C-I', 'C-CI', 'C-LD', 'A', 'A-PD', 'A-S']\n",
    "model_names=['true', 'fully independent', 'conditionally independent', 'length dependent', 'augmented', 'position-dependent augmented', 'stratified augmented']\n",
    "palette = sns.color_palette('Greys', n_colors=1) + sns.color_palette(\"Blues\", n_colors=3)+sns.color_palette(\"YlOrBr\", n_colors=3)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(6,5))\n",
    "data = sampling_df[(sampling_df.metric_type=='length')&\n",
    "                   (sampling_df.dataset==dataset)]\n",
    "sns.barplot(data=data, x=\"metric\", y=\"value\", hue=\"name label\", palette=palette, hue_order=hue_order, ax=ax).set(title=name, xlabel='', ylabel='')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a8c0f110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hue_order = ['true', 'C-I', 'C-CI', 'C-LD', 'A', 'A-PD', 'A-S']\n",
    "palette = sns.color_palette('Greys', n_colors=1) + sns.color_palette(\"Blues\", n_colors=3)+sns.color_palette(\"YlOrBr\", n_colors=3)\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(12,5))\n",
    "name = '2018 Mayor'\n",
    "dataset = '2018 M'\n",
    "data = sampling_df[(sampling_df.dataset==dataset)&\n",
    "                   (sampling_df.metric_type=='top-1 candidate')&\n",
    "                   ~(sampling_df['name label'].isin(['C-CI']))]\n",
    "sns.barplot(data=data, x=\"display name\", y=\"value\", hue=\"name label\",\n",
    "            palette=palette[:2]+palette[-5:], hue_order=hue_order, ax=ax[0]).set(title='{} - Top-1 Candidate Demand'.format(name),\n",
    "                                                                xlabel='', \n",
    "                                                                ylabel='Proportion')\n",
    "ax[0].set_xticklabels(ax[0].get_xticklabels(), rotation=45, fontdict={'horizontalalignment':'center'})\n",
    "data = sampling_df[(sampling_df.dataset==dataset)&\n",
    "                   (sampling_df.metric_type=='overall candidate')&\n",
    "                   ~(sampling_df['name label'].isin(['C-CI']))]\n",
    "sns.barplot(data=data, x=\"display name\", y=\"value\", hue=\"name label\",\n",
    "            palette=palette[:2]+palette[-5:], hue_order=hue_order, ax=ax[1]).set(title='{} - Overall Candidate Demand'.format(name), \n",
    "                                                                xlabel='', \n",
    "                                                                ylabel='Proportion')\n",
    "ax[1].set_xticklabels(ax[1].get_xticklabels(), rotation=45, fontdict={'horizontalalignment':'center'})\n",
    "\n",
    "ax[0].legend().remove()\n",
    "ax[1].legend(loc='upper right')\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
